{
  "null": {
    "guideline_match_Financial_Human": {
      "low": -0.4956521739130435,
      "high": -0.3855072463768116,
      "mean": -0.4405797101449275
    },
    "guideline_match_Human_Financial": {
      "low": -0.23684210526315788,
      "high": -0.02631578947368421,
      "mean": -0.10526315789473684
    },
    "guideline_match_Intellectual_Intellectual": {
      "low": 0.6190476190476191,
      "high": 0.9523809523809523,
      "mean": 0.8571428571428571
    },
    "guideline_match_Manufactured_Manufactured": {
      "low": 0.5121951219512195,
      "high": 0.9024390243902439,
      "mean": 0.7560975609756098
    },
    "guideline_match_Natural_Natural": {
      "low": 0.6129032258064516,
      "high": 1.0,
      "mean": 0.8709677419354839
    },
    "guideline_match_Social and relationship_Social and relationship": {
      "low": 0.3,
      "high": 0.8,
      "mean": 0.6
    },
    "guideline_match": {
      "low": -0.13543599257884972,
      "high": -0.0037105751391465678,
      "mean": -0.07050092764378478
    }
  },
  "classification_metrics": {
    "source_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 29.846296296296295,
        "high": 32.78245265066384,
        "mean": 31.214814814814815
      },
      "tokens_per_sample": {
        "low": 29.846296296296295,
        "high": 32.78245265066384,
        "mean": 31.214814814814815
      },
      "fkgl_readability": {
        "low": 14.885194177106461,
        "high": 15.993435852791453,
        "mean": 15.43277777777778
      }
    },
    "prediction_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 1.1574074074074074,
        "high": 1.3592592592592592,
        "mean": 1.2148148148148148
      },
      "tokens_per_sample": {
        "low": 1.1574074074074074,
        "high": 1.3592592592592592,
        "mean": 1.2148148148148148
      },
      "fkgl_readability": {
        "low": 21.325185185185184,
        "high": 22.790878075681423,
        "mean": 22.023703703703703
      }
    },
    "reference_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 1.2740740740740741,
        "high": 1.4,
        "mean": 1.3333333333333333
      },
      "tokens_per_sample": {
        "low": 1.2740740740740741,
        "high": 1.4,
        "mean": 1.3333333333333333
      },
      "fkgl_readability": {
        "low": 21.903709993080817,
        "high": 23.873587714875907,
        "mean": 22.883333333333333
      }
    },
    "length_diff": {
      "sentences_diff": {
        "low": NaN,
        "high": NaN,
        "mean": 0.0
      },
      "tokens_diff": {
        "low": 0.30185185185185187,
        "high": 0.5074074074074074,
        "mean": 0.37037037037037035
      }
    },
    "exact_match": {
      "low": 0.45185185185185184,
      "high": 0.5370370370370371,
      "mean": 0.49444444444444446
    },
    "partial_match": {
      "low": 0.45185185185185184,
      "high": 0.5370370370370371,
      "mean": 0.49444444444444446
    }
  }
}