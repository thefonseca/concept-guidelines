{
  "null": {
    "guideline_match_Financial_Manufactured": {
      "low": 0.003816793893129771,
      "high": 0.14122137404580154,
      "mean": 0.07251908396946564
    },
    "guideline_match_Human_Financial": {
      "low": 0.2894736842105263,
      "high": 0.6842105263157895,
      "mean": 0.5
    },
    "guideline_match_Intellectual_Intellectual": {
      "low": 0.5873015873015873,
      "high": 0.9047619047619048,
      "mean": 0.7777777777777778
    },
    "guideline_match_Manufactured_Social and relationship": {
      "low": -0.0423728813559322,
      "high": 0.09322033898305085,
      "mean": 0.025423728813559324
    },
    "guideline_match_Natural_Natural": {
      "low": -0.2727272727272727,
      "high": 0.8181818181818182,
      "mean": 0.45454545454545453
    },
    "guideline_match_Social and relationship_Human": {
      "low": 0.3333333333333333,
      "high": 0.6666666666666666,
      "mean": 0.5111111111111111
    },
    "guideline_match": {
      "low": 0.16759776536312848,
      "high": 0.27001862197392923,
      "mean": 0.21973929236499068
    }
  },
  "classification_metrics": {
    "source_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 29.846296296296295,
        "high": 32.78245265066384,
        "mean": 31.214814814814815
      },
      "tokens_per_sample": {
        "low": 29.846296296296295,
        "high": 32.78245265066384,
        "mean": 31.214814814814815
      },
      "fkgl_readability": {
        "low": 14.885194177106461,
        "high": 15.993435852791453,
        "mean": 15.43277777777778
      }
    },
    "prediction_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 1.1222222222222222,
        "high": 1.4092592592592592,
        "mean": 1.1907407407407407
      },
      "tokens_per_sample": {
        "low": 1.1222222222222222,
        "high": 1.4092592592592592,
        "mean": 1.1907407407407407
      },
      "fkgl_readability": {
        "low": 24.537636223711406,
        "high": 26.283484854743318,
        "mean": 25.396296296296295
      }
    },
    "reference_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 1.2740740740740741,
        "high": 1.4,
        "mean": 1.3333333333333333
      },
      "tokens_per_sample": {
        "low": 1.2740740740740741,
        "high": 1.4,
        "mean": 1.3333333333333333
      },
      "fkgl_readability": {
        "low": 21.903709993080817,
        "high": 23.873587714875907,
        "mean": 22.883333333333333
      }
    },
    "length_diff": {
      "sentences_diff": {
        "low": NaN,
        "high": NaN,
        "mean": 0.0
      },
      "tokens_diff": {
        "low": 0.31851851851851853,
        "high": 0.6037037037037037,
        "mean": 0.39814814814814814
      }
    },
    "exact_match": {
      "low": 0.3888888888888889,
      "high": 0.4722222222222222,
      "mean": 0.43148148148148147
    },
    "partial_match": {
      "low": 0.3888888888888889,
      "high": 0.4722222222222222,
      "mean": 0.43148148148148147
    }
  }
}