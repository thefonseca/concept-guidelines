{
  "null": {
    "guideline_match_Financial_Financial": {
      "low": -0.14202898550724638,
      "high": 0.07246376811594203,
      "mean": -0.03768115942028986
    },
    "guideline_match_Human_Human": {
      "low": 0.6336214069286733,
      "high": 1.0,
      "mean": 0.8947368421052632
    },
    "guideline_match_Intellectual_Manufactured": {
      "low": -0.30952380952380953,
      "high": 0.023809523809523808,
      "mean": -0.14285714285714285
    },
    "guideline_match_Manufactured_Intellectual": {
      "low": -0.5365853658536586,
      "high": -0.24390243902439024,
      "mean": -0.3902439024390244
    },
    "guideline_match_Natural_Natural": {
      "low": NaN,
      "high": NaN,
      "mean": 1.0
    },
    "guideline_match_Social and relationship_Social and relationship": {
      "low": 0.4,
      "high": 0.9,
      "mean": 0.7
    },
    "guideline_match": {
      "low": 0.02973977695167286,
      "high": 0.18587360594795538,
      "mean": 0.10780669144981413
    }
  },
  "classification_metrics": {
    "source_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 29.846296296296295,
        "high": 32.78245265066384,
        "mean": 31.214814814814815
      },
      "tokens_per_sample": {
        "low": 29.846296296296295,
        "high": 32.78245265066384,
        "mean": 31.214814814814815
      },
      "fkgl_readability": {
        "low": 14.885194177106461,
        "high": 15.993435852791453,
        "mean": 15.43277777777778
      }
    },
    "prediction_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 1.2962962962962963,
        "high": 1.511111111111111,
        "mean": 1.3666666666666667
      },
      "tokens_per_sample": {
        "low": 1.2962962962962963,
        "high": 1.511111111111111,
        "mean": 1.3666666666666667
      },
      "fkgl_readability": {
        "low": 19.410143672852428,
        "high": 20.714334872591305,
        "mean": 20.04185185185185
      }
    },
    "reference_stats": {
      "sentences_per_sample": {
        "low": NaN,
        "high": NaN,
        "mean": 1.0
      },
      "tokens_per_sentence": {
        "low": 1.2740740740740741,
        "high": 1.4,
        "mean": 1.3333333333333333
      },
      "tokens_per_sample": {
        "low": 1.2740740740740741,
        "high": 1.4,
        "mean": 1.3333333333333333
      },
      "fkgl_readability": {
        "low": 21.903709993080817,
        "high": 23.873587714875907,
        "mean": 22.883333333333333
      }
    },
    "length_diff": {
      "sentences_diff": {
        "low": NaN,
        "high": NaN,
        "mean": 0.0
      },
      "tokens_diff": {
        "low": 0.36666666666666664,
        "high": 0.5740740740740741,
        "mean": 0.44074074074074077
      }
    },
    "exact_match": {
      "low": 0.4648148148148148,
      "high": 0.5481481481481482,
      "mean": 0.5055555555555555
    },
    "partial_match": {
      "low": 0.4648148148148148,
      "high": 0.5481481481481482,
      "mean": 0.5055555555555555
    }
  }
}