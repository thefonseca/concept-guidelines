INFO:__main__:Processing label permutation 0 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or '
  ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Background: A sentence that provides contex ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The given text does not fall into any of the provided concept categories. It appears to be a scientific description of a chemical compound, including its structural formula, spectroscopic data, and mass spectrometry results." => "Result"
WARNING:llms.classifiers.models:Prediction "The given text does not provide enough information to classify it into one of the concept categories listed. It appears to be a combination of numbers and abbreviations that do not convey any meaning or context related to a specific scientific concept or research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories can accurately classify the given text as it does not fit into any of the defined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fall under any of the concept categories mentioned above. It does not provide background information, describe research methods, explain the motivation behind the research, present empirical findings, or offer a conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the text provided does not fit into any of the categories listed above. It appears to be a standalone statement that does not pertain to a specific scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the listed concept categories. It seems to be a statement within the scientific content, rather than a background, method, motivation, result, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories fully apply to the provided text. The given text does not fall into the categories of Background, Method, Motivation, Result, or Conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This is not a complete sentence or coherent text that can be classified into one of the concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not clearly belong to any of the provided concept categories. It appears to be a technical statement that does not fit neatly into the Background, Method, Motivation, Result, or Conclusion categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the mentioned concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the provided categories apply to the given text "6." As such, a specific scientific concept cannot be classified using the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 989 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 583 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 580 null score values in confidence interval computation
INFO:llms.metrics:classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.007, 1.014
tokens_per_sentence: 1.096, 1.190, 1.337
tokens_per_sample: 1.159, 1.324, 1.590
fkgl_readability: 6.415, 6.884, 7.369

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 22.182, 29.455, 35.727
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 1 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Result',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that provides context, foundational knowledge, or '
 'rel ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that provides context, f ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "I'm sorry, but the given text does not fall into any of the provided concept categories. It appears to be a partial sentence or equation without clear context or meaning." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the provided categories accurately fit the given text. The text does not fall under any specific category as it does not provide context, describe research methods, explain objectives or goals, present empirical findings, or summarize key takeaways." => "Method"
WARNING:llms.classifiers.models:Prediction "The given text does not provide enough information to classify it into any of the concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately capture the concept presented in the given text. The text does not pertain to the method, result, background, motivation, or conclusion of a research study. It simply states a general statement about the reliability of analyzing reaction pathways with a larger set of test cases." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories accurately classify the text "This perspective will highlight just a few of these last ones." The text does not fit into any of the categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "It is difficult to classify the given text into one of the listed categories as it does not provide enough information for categorization." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fall into any of the categories listed above. It appears to be a statement or formula related to the concept of electron behavior in a vacuum." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The provided text does not contain enough information to be classified into any of the concept categories listed." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the given categories fit the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above accurately apply to the given text. The text does not provide context or foundational knowledge (Method), describe research methods or data collection processes (Result), explain reasons or objectives behind the research (Background), present empirical findings or data (Motivation), or summarize key takeaways or implications of the study's results (Conclusion)." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text "6" does not provide enough information to classify it into any of the categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 848 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 869 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 921 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 968 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 598 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 990 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 633 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 632 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.158, 0.316, 0.461
guideline_match_Motivation_Background: 0.359, 0.511, 0.649
guideline_match_Method_Result: 0.570, 0.747, 0.873
guideline_match_Result_Motivation: -0.875, -0.688, -0.375
guideline_match_Conclusion_Conclusion: -0.750, 0.000, 0.750
guideline_match: 0.284, 0.378, 0.463

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.015
tokens_per_sentence: 1.092, 1.188, 1.359
tokens_per_sample: 1.150, 1.314, 1.657
fkgl_readability: 4.364, 4.742, 5.113

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.200, 1.800
tokens_diff: 22.600, 31.400, 45.700
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 2 of 50:
{'Background': 'Result',
 'Conclusion': 'Background',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that provides context, foundational knowledge, or '
  ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that provides contex ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Result'
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the concept categories given. It appears to be a specific equation or formula rather than a sentence that fits into one of the defined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the concept categories listed above. It seems to be a sentence discussing a research topic rather than providing any specific information related to conclusion, background, motivation, method, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "Without further context, it is not possible to classify the given text into one of the concept categories provided. The text seems to consist of numbers and abbreviations, which do not fit into any of the categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Conception" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text. The text seems to be a statement about a perspective or viewpoint, rather than a specific component of a scientific research paper. Therefore, it does not fit into any of the concept categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above directly apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text "6" does not fit into any of the concept categories listed above. It appears to be a numerical value or an incomplete sentence that does not provide information related to conclusions, background, motivation, method, or results in a scientific context." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.metrics:Ignoring 838 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 939 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 903 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 953 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 632 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 607 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 605 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.778, -0.679, -0.556
guideline_match_Motivation_Method: -0.443, -0.180, 0.082
guideline_match_Method_Result: 0.320, 0.505, 0.670
guideline_match_Result_Background: -0.489, -0.234, 0.064

> guideline_match_Conclusion_Motivation:
mean: -1.000
guideline_match: -0.326, -0.228, -0.125

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.015
tokens_per_sentence: 1.057, 1.131, 1.262
tokens_per_sample: 1.102, 1.250, 1.533
fkgl_readability: 7.214, 7.703, 8.192

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.200, 1.800
tokens_diff: 18.994, 31.250, 41.125
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 3 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Method',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that describes the research methods, techniques, '
 ' ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that describes the r ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "The text does not clearly fall into any of the concept categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not clearly fall into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Without any additional information, it is not possible to classify the text into one of the categories listed above. It appears to be a citation or reference, rather than a sentence that can be categorized." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fall into any of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the listed categories accurately apply to the given text. It does not describe research methods, research background, research results, research conclusions, or research methodology." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "My apologies, but I'm unable to classify the given text into one of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not provide enough information to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories accurately classify the text provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the provided concept categories (Motivation, Background, Result, Conclusion, Method). It appears to be a statement related to the characteristics or performance of templates on gold substrates, but it does not provide information on research methods, objectives, findings, or broader implications." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The text does not fit into any of the provided categories. It appears to be a statement about a specific observation or result in a scientific study." => "Result"
WARNING:llms.classifiers.models:Prediction "This text does not provide any information related to a scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 862 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 886 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 940 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 385 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 988 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 606 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 604 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.565, 0.696, 0.797
guideline_match_Motivation_Background: 0.123, 0.298, 0.456
guideline_match_Method_Motivation: -0.267, 0.000, 0.267
guideline_match_Result_Result: 0.532, 0.627, 0.708
guideline_match_Conclusion_Conclusion: -0.750, 0.000, 0.750
guideline_match: 0.441, 0.512, 0.577

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.098, 1.186, 1.335
tokens_per_sample: 1.125, 1.252, 1.506
fkgl_readability: 4.079, 4.508, 4.954

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 15.000, 21.000, 32.833
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 4 of 50:
{'Background': 'Background',
 'Conclusion': 'Method',
 'Method': 'Conclusion',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or '
  ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Background: A sentence that provides contex ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Explanation of delocalized configuration in the context of a research topic or broader scientific field - Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Conclusions" => "Conclusion"
WARNING:llms.classifiers.models:Prediction "This text does not clearly fit into any of the provided concept categories. It appears to be a incomplete or ambiguous statement related to phases and modes, but without further context it is difficult to classify it into a specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not belong to any of the categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "There is not enough information in the text to classify it into one of the given concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the categories listed above. It appears to be a fragmented sentence mentioning several scientific examples and references, but it does not clearly fall into one specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "Explanation: The given text does not fit into any of the specified categories. It is unclear what the text is referring to or what scientific concept it is related to." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "No category can be assigned to this sentence as it does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not fit into any of the categories listed above. It appears to be a partial statement without sufficient context to categorize it accurately." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories seem to be applicable to the given text. It does not pertain to background information, motivation, method, conclusion, or results of a scientific study. Please provide more context or a different text to classify." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the text provided does not fit into any of the listed concept categories. It appears to be a general statement that is not related to scientific research or any specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above fit the given text. The text appears to be a partial sentence or statement rather than a full concept that can be classified." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sorry, but I can't classify the provided text without more information. The text seems incomplete and does not contain enough context to determine the scientific concept it belongs to. Could you please provide more details or provide a complete sentence or paragraph?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "No category can be assigned to this text as it does not relate to any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories directly applies to the text provided. The given text does not fall into any of the categories specified." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not provide enough information to classify it into one of the categories. Please provide more context or information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the mentioned categories accurately classify the given text. The text provided does not correspond to any of the mentioned scientific concepts." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 916 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 208 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 989 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 985 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 561 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 560 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.474, 0.578, 0.667
guideline_match_Motivation_Motivation: 0.343, 0.500, 0.629
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Result: 0.641, 0.729, 0.803
guideline_match_Conclusion_Method: nan, -1.000, nan
guideline_match: 0.384, 0.447, 0.508

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.007, 1.013, 1.023
tokens_per_sentence: 1.134, 1.234, 1.375
tokens_per_sample: 1.247, 1.438, 1.723
fkgl_readability: 7.126, 7.582, 8.032

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.182, 1.545
tokens_diff: 24.400, 29.200, 34.600
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 5 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Method',
 'Method': 'Result',
 'Motivation': 'Background',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 "inte ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Result: A sentence that summarizes the key  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept in the given text is "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Findings/results" => "Result"
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept mentioned in the given text is "Result"." => "Result"
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not fall into any of the provided concept categories. It appears to be a technical equation or formula." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not directly fit into any of the concept categories provided. It appears to contain technical information related to a scientific study or experiment, but it does not clearly convey a specific result, motivation, conclusion, background, or method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above apply to the given text. The text appears to be a placeholder or reference marker, and does not provide any information that can be classified into the concept categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above accurately classify the given text. The text seems to refer to a technical aspect related to integral calculus or mathematical transformations, rather than a concept category such as motivation, result, conclusion, background, or method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not provide enough information to determine a specific scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "No scientific concept is mentioned in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories mentioned (Result, Motivation, Conclusion, Background, Method) are appropriate for classifying the given text "This is not insubstantial." This text does not pertain to a scientific concept, research study, or any of the categories mentioned." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories seem to fit the given text, as it is a statement about a situation and does not directly relate to the key takeaways, motivations, conclusions, background, or research methods of a study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not contain enough information to be classified into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories can accurately classify the given text. The text does not fit into any of the provided categories as it does not discuss research results, motivation, conclusion, methodology, or research background. It is a statement rather than a scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "The given text cannot be classified into any of the concept categories as it does not contain any information or content." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 831 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 921 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 955 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 854 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 557 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 987 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 675 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 670 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.254, -0.101, 0.053
guideline_match_Motivation_Background: 0.063, 0.291, 0.494
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Method: 0.740, 0.849, 0.918
guideline_match_Conclusion_Result: nan, 1.000, nan
guideline_match: 0.111, 0.201, 0.291

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.007, 1.015
tokens_per_sentence: 1.129, 1.240, 1.432
tokens_per_sample: 1.195, 1.379, 1.687
fkgl_readability: 4.759, 5.273, 5.808

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.167, 1.667
tokens_diff: 20.769, 29.154, 37.769
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 6 of 50:
{'Background': 'Method',
 'Conclusion': 'Background',
 'Method': 'Result',
 'Motivation': 'Conclusion',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that presents the empiri ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The given text does not fall into any of the categories listed above. It does not provide empirical findings, describe research methods or techniques, provide context or foundational knowledge, summarize key takeaways or implications, or explain the reasons or objectives behind the research. Therefore, it does not fit into any specific category." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "None of the given concept categories apply directly to the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories (Method, Background, Conclusion, Motivation, Result) are a good fit for classifying the given text. The text appears to be describing a specific scientific concept regarding adiabatic states and their relationship with rotation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method (referring to empirical findings, outcomes, observations, or data generated by the research)" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept mentioned in the text is "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Without further context, it is difficult to determine the specific category for the given text. The text appears to be incomplete or without specific content related to a scientific concept. Therefore, it cannot be classified into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information in the provided text to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept present in the given text is "Method."" => "Method"
WARNING:llms.classifiers.models:Prediction "None of the provided categories match the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information to accurately classify the given text into one of the concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories apply to the given text as it does not relate to a scientific concept or research topic." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the concept categories listed above apply to the given text. The text does not provide any empirical findings, research methods, background information, conclusions, motivations, or results." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories directly apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories mentioned above are applicable to the text "6" as it does not convey any scientific concept or information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The appropriate category for the given text is "Method"." => "Method"
WARNING:llms.metrics:Ignoring 873 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 919 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 927 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 742 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 459 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 989 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 729 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 728 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.921, -0.843, -0.732
guideline_match_Motivation_Result: -0.951, -0.877, -0.728
guideline_match_Method_Background: 0.479, 0.671, 0.808
guideline_match_Result_Method: 0.822, 0.891, 0.938
guideline_match_Conclusion_Motivation: nan, -1.000, nan
guideline_match: 0.098, 0.183, 0.264

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.012
tokens_per_sentence: 1.089, 1.181, 1.322
tokens_per_sample: 1.120, 1.252, 1.486
fkgl_readability: 2.532, 3.025, 3.540

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.333, 2.000
tokens_diff: 16.727, 22.909, 31.364
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 7 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Background',
 'Method': 'Conclusion',
 'Motivation': 'Result',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that explains the reasons, objectives, or goals '
 'b ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Background: A sentence that explains the re ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the categories listed above. It appears to be a statement related to a scientific concept, but it does not fall into any specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories directly apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "- Result" => "Result"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The text does not fit into any of the provided categories as it does not pertain to background, motivation, method, conclusion, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the provided categories are applicable to classify the given text. The text does not fit into any of the categories of Background, Motivation, Method, Conclusion, or Result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the provided concept categories seem to perfectly fit the text. However, the closest category would be "Conclusion" as it provides contextual information about the research topic and references a prior study." => "Conclusion"
WARNING:llms.classifiers.models:Prediction "None of the categories mentioned above fit the given text. The text does not fall into any of the provided categories as it does not pertain to background, motivation, method, conclusion, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "The given text, "10__SP__–10__SP__. __REF__," does not provide enough information to classify it into any of the concept categories listed above. It seems to be unrelated to any specific scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The text does not fall under any of the categories of background, motivation, method, conclusion, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Methods" => "Method"
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the given text. The text provided does not contain information related to research, empirical findings, methodology, background context, or conclusions." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. It appears to be a technical statement related to the properties of electrons in a vacuum, but it does not fit into the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The provided text does not fall into any of the categories listed above. It appears to be an incomplete sentence or fragment." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text. The text does not fit into any of the listed concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the text "6." It appears to be a standalone number without any context or information related to a research concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 899 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 868 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 916 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 894 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 572 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 989 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 988 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 662 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 659 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.941, -0.861, -0.743
guideline_match_Motivation_Background: 0.379, 0.530, 0.667
guideline_match_Method_Result: 0.476, 0.667, 0.810
guideline_match_Result_Motivation: 0.113, 0.302, 0.472
guideline_match_Conclusion_Method: -1.000, -0.600, 0.600
guideline_match: 0.065, 0.159, 0.252

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.006, 1.012, 1.021
tokens_per_sentence: 1.097, 1.182, 1.310
tokens_per_sample: 1.199, 1.376, 1.647
fkgl_readability: 5.659, 6.105, 6.556

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.091, 1.455
tokens_diff: 25.417, 31.333, 34.667
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 8 of 50:
{'Background': 'Method',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Background'
WARNING:llms.classifiers.models:Prediction "None of the concept categories listed above apply to the given text. The text appears to be referring to a specific equation or calculation, rather than discussing motivation, method, results, background, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not provide enough information to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the provided options match the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above classify the given text accurately as it does not fall into any of them. The given text does not pertain to a conclusion, motivation, method, result, or background of a scientific study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "This text falls under the "Background" category." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "The text provided falls under the concept category of "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "None of the categories provided perfectly fit with the given text. However, if we have to classify it into one of the listed categories, we can loosely associate it with the "Method" category as it provides some context about potential factors influencing the observed differences." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept described in the given text can be classified as "Method" as it provides context and foundational knowledge about the research topic, existing theories, and prior studies on which the research is based." => "Method"
WARNING:llms.classifiers.models:Prediction "The text "6" does not fit into any of the concept categories listed above. It appears to be unrelated to the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.metrics:Ignoring 928 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 813 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 298 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 647 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 645 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.083, 0.306, 0.528
guideline_match_Motivation_Motivation: -0.529, -0.386, -0.229
guideline_match_Method_Background: 0.701, 0.797, 0.872
guideline_match_Result_Result: 0.559, 0.654, 0.736
guideline_match_Conclusion_Conclusion: 0.000, 0.750, 1.000
guideline_match: 0.382, 0.450, 0.513

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.009
tokens_per_sentence: 1.034, 1.093, 1.212
tokens_per_sample: 1.052, 1.149, 1.365
fkgl_readability: 7.003, 7.360, 7.716

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 15.000, 24.833, 35.833
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 9 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that provides context, foundational knowledge, or '
 'rel ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that provides context, f ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "Consequence." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not provide enough information to classify it into one of the listed categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above directly apply to the text provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, without more context or information, it is not possible to classify the given text into one of the concept categories listed above. Please provide additional information for a more accurate classification." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the categories listed above as it does not provide context, empirical findings, research methods, motivation, or a conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "N/A" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text is not specific enough to clearly classify it into one of the concept categories listed above. It appears to be incomplete or lacks the necessary information. Please provide more context or content for a proper classification." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately captures the content of the text. The text does not fit into any of the defined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 796 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 914 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 947 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 509 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 627 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 627 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.029, 0.167, 0.294
guideline_match_Motivation_Motivation: 0.214, 0.371, 0.514
guideline_match_Method_Result: 0.628, 0.791, 0.907
guideline_match_Result_Background: -0.019, 0.245, 0.509
guideline_match_Conclusion_Conclusion: -0.250, 0.500, 1.000
guideline_match: 0.263, 0.348, 0.430

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.012
tokens_per_sentence: 1.056, 1.123, 1.251
tokens_per_sample: 1.079, 1.182, 1.385
fkgl_readability: 5.597, 6.089, 6.602

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.333, 2.000
tokens_diff: 12.444, 20.222, 28.444
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 10 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Background',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that presents the empirical findings, outcomes, '
 'o ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that presents the em ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "The given text does not provide enough information to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the provided concept categories as it does not convey empirical findings, explain the reasons or objectives of research, provide context or relevant information, describe research methods, or summarize key takeaways or implications of a study's results." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "- Motivation" => "Motivation"
WARNING:llms.classifiers.models:Prediction "There is no specific scientific concept mentioned in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result and Conclusion" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories fit the context of the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept mentioned in the text is "Result"." => "Result"
WARNING:llms.classifiers.models:Prediction "Sorry, but I'm unable to identify the scientific concept from the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "None of the categories listed above (Motivation, Result, Conclusion, Method, Background) can be directly applied to the given text "6" as it is not a sentence or a scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 901 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 879 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 778 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 279 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 688 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 685 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.960, -0.899, -0.778
guideline_match_Motivation_Result: -0.636, -0.488, -0.322
guideline_match_Method_Method: 0.761, 0.833, 0.891
guideline_match_Result_Motivation: 0.153, 0.279, 0.405
guideline_match_Conclusion_Background: -1.000, 0.333, 1.000
guideline_match: 0.129, 0.201, 0.270

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: 1.051, 1.146, 1.366
tokens_per_sample: 1.051, 1.146, 1.366
fkgl_readability: 5.813, 6.368, 6.932

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
tokens_diff: 11.429, 20.857, 35.286
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 11 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Result',
 'Method': 'Conclusion',
 'Motivation': 'Method',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that presents the empirical findings, outcomes, '
 'o ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that presents the em ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not fall into any of the concept categories provided. It seems to be a standalone statement without sufficient context to classify it into one of the categories mentioned." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories fit for the provided text as it does not relate to any specific scientific concept or research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Existing Theory" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "Consequence" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text as it is not related to any empirical findings, objectives/goals, interpretations, research background, or research methods." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "N/A" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "- Conclusion" => "Conclusion"
WARNING:llms.classifiers.models:Fixing prediction: "Conclusions" => "Conclusion"
WARNING:llms.classifiers.models:Prediction "There is not enough information in the text provided to classify it into one of the categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the provided categories. However, the text seems to describe a scientific concept related to the protonation of acid/base catalysts." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 789 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 906 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 849 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 967 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 509 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 646 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 645 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: 0.573, 0.678, 0.763
guideline_match_Motivation_Background: -0.213, -0.021, 0.191
guideline_match_Method_Motivation: -0.417, -0.272, -0.113
guideline_match_Result_Conclusion: 0.030, 0.394, 0.697
guideline_match_Conclusion_Method: nan, -1.000, nan
guideline_match: 0.141, 0.226, 0.312

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.002, 1.007
tokens_per_sentence: 1.035, 1.103, 1.245
tokens_per_sample: 1.049, 1.136, 1.315
fkgl_readability: 8.186, 8.605, 9.023

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 11.000, 22.667, 29.333
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 12 of 50:
{'Background': 'Method',
 'Conclusion': 'Conclusion',
 'Method': 'Result',
 'Motivation': 'Background',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that describes the research methods, techniques, '
 ' ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Background: A sentence that describes the r ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Result'
WARNING:llms.classifiers.models:Fixing prediction: "The text provided does not fit into any of the categories listed above. It does not describe research methods, summarize key takeaways, explain the reasons or objectives of research, present empirical findings, or provide context or relevant information about a research topic or field." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately categorize the given text. The given text does not fall into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories fully capture the scientific concept described in the text. The text appears to be discussing a specific term or concept related to epithelial tumors and gland tissue, but it does not fit neatly into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information in the given text to determine the scientific concept. The text mainly consists of references (indicated by "__REF__"), and does not provide enough context for categorization." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The provided text does not fit into any of the categories listed above. It does not pertain to background, conclusion, result, method, or motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories mentioned above directly apply to the given text. The provided text appears to be a statement or observation without clear connections to any specific scientific concept categorizations." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "Without any further information or context, it is difficult to classify the text into one of the given categories. It appears to be a reference or citation, rather than a complete sentence that can be categorized." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None. The given text does not directly relate to any specific scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately align with the given text. The text is not related to any scientific concepts, research methods, procedures, findings, or background information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is no clear indication of a specific scientific concept in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories fit the given text. The text appears to be referencing specific values or measurements, rather than discussing research methods, results, conclusions, motivations, or background information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories seems to be an appropriate fit for the given text. The sentence does not provide information related to research methods, data collection, experimental design, data analysis, materials or instruments used (Background), it does not summarize key takeaways, implications, interpretations, or insights derived from the study's results (Conclusion), it does not explain the reasons, objectives, or goals behind the research (Result), it does not present empirical findings, outcomes, or data generated by the research (Method), and it does not provide context, foundational knowledge, or relevant information about the research topic (Motivation). Hence, the text cannot be classified into any of the given categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the provided text does not contain enough information to classify it into one of the concept categories listed above. Please provide a more complete sentence or phrase for analysis." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories completely applies to the text provided. The text does not describe research methods, techniques, procedures, data collection processes, experimental design, data analysis, materials, instruments, key takeaways, implications, interpretations, insights, significance of findings, future research directions, contributions to the field, empirical findings, outcomes, observations, data, quantitative or qualitative results, statistical analyses, tables, figures, motivation, context, foundational knowledge, relevant information, research topic, existing theories, or prior studies." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. It appears to be a statement about the characteristics or performance of templates on gold substrates, rather than providing information related to background, conclusion, result, method, or motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text "6" does not provide enough information to classify it into one of the listed categories. Can you please provide a complete sentence or paragraph for analysis?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories (Background, Conclusion, Result, Method, Motivation) are applicable to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 820 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 950 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 882 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 898 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 542 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 986 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 983 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 664 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 659 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: 0.078, 0.222, 0.356
guideline_match_Motivation_Result: -0.840, -0.680, -0.440
guideline_match_Method_Background: 0.424, 0.593, 0.729
guideline_match_Result_Method: 0.176, 0.373, 0.549
guideline_match_Conclusion_Conclusion: -0.250, 0.500, 1.000
guideline_match: 0.166, 0.258, 0.341

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.008, 1.015, 1.025
tokens_per_sentence: 1.194, 1.338, 1.581
tokens_per_sample: 1.381, 1.689, 2.281
fkgl_readability: 7.331, 7.874, 8.408

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.071, 1.357
tokens_diff: 29.882, 40.529, 64.290
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 13 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the provided concept categories. It appears to be incomplete and lacks clear scientific content." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text does not fit into any of the provided categories. It is discussing a specific scientific finding or result related to the diminished stability of TG14." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text. The text does not belong to any of the concept categories listed." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories accurately categorizes the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sorry, but I'm unable to classify the given text into one of the categories listed above as it is incomplete and does not provide enough context to determine the appropriate category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Method 
Result" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the categories listed above. It appears to be a statement related to a scientific concept but does not fit the criteria for any specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not necessarily fit into any of the concept categories provided. It seems to be discussing a specific scientific phenomenon, but it does not explicitly relate to any of the categories listed." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately categorize the text provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 875 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 867 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 972 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 430 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 636 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 636 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: 0.632, 0.760, 0.856
guideline_match_Motivation_Background: 0.248, 0.414, 0.564
guideline_match_Method_Method: 0.094, 0.210, 0.326
guideline_match_Result_Motivation: -0.857, -0.571, -0.214
guideline_match_Conclusion_Conclusion: -0.250, 0.500, 1.000
guideline_match: 0.267, 0.344, 0.418

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.010
tokens_per_sentence: 1.055, 1.122, 1.260
tokens_per_sample: 1.079, 1.182, 1.378
fkgl_readability: 6.350, 6.686, 7.016

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 12.556, 20.222, 28.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 14 of 50:
{'Background': 'Method',
 'Conclusion': 'Result',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that presents the empirical findings, outcomes, '
 'o ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that presents the em ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the given categories are an appropriate fit for the given text. The given text does not fit into any of the provided concept categories as it does not pertain to empirical findings, motivations, results, background, or methods." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sorry, but I'm unable to classify the given text into one of the concept categories as it does not provide any information or context related to scientific research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above (Conclusion, Motivation, Result, Background, Method) are applicable to the given text. The text does not pertain to a specific scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "Unfortunately, the text provided does not fit into any of the categories listed above. It does not pertain to empirical findings, motivation, results, background, or method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to classify the given text. The text appears to be incomplete and does not contain sufficient content to be categorized into one of the listed categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories fit the text "The reasons for this discrepancy are unclear." This text does not fit into any of the provided categories as it does not pertain to empirical findings, motivation, results, background, or methods. It seems to express uncertainty or lack of understanding rather than fitting into any specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above can be applied to the text "6" as it does not contain any information or context related to research, findings, motivation, methods, or background." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 865 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 884 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 833 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 913 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 494 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 658 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 655 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: 0.467, 0.615, 0.733
guideline_match_Motivation_Method: -0.776, -0.655, -0.500
guideline_match_Method_Background: -0.018, 0.138, 0.281
guideline_match_Result_Conclusion: 0.356, 0.563, 0.724

> guideline_match_Conclusion_Motivation:
mean: -1.000
guideline_match: 0.067, 0.154, 0.241

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.015
tokens_per_sentence: 1.066, 1.157, 1.332
tokens_per_sample: 1.109, 1.274, 1.569
fkgl_readability: 7.905, 8.283, 8.679

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.200, 1.800
tokens_diff: 33.857, 39.143, 52.092
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 15 of 50:
{'Background': 'Method',
 'Conclusion': 'Result',
 'Method': 'Conclusion',
 'Motivation': 'Motivation',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that explains the re ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Conclusions" => "Conclusion"
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the concept categories provided. It appears to be a mathematical equation or formula, which is not covered by the given categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the concept categories listed above. It appears to contain technical terms and information related to a specific scientific study, but it does not fit neatly into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text "10__SP__–10__SP__. __REF__" does not provide enough information for classification into any of the concept categories listed above. It appears to be incomplete or missing crucial information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text cannot be classified into any of the categories listed above as it does not pertain to any specific research motivation, conclusion, method, background, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information provided in the text to classify it into one of the listed concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "None of the categories mentioned above seem to fit the given text accurately. However, if we consider the broader context, the text could potentially fall under the "Result" category as it provides introductory information or context about certain perspectives." => "Result"
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the specified scientific concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the listed categories. It is a description of a scientific procedure or setup, rather than a statement about motivation, conclusion, method, background, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided scientific concept categories. It is simply a statement without any information related to motivation, conclusion, method, background, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the concept categories listed above. It appears to be incomplete or unrelated to any specific scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the categories listed above directly describe the text provided. However, this text could be classified under the "Result" category as it provides relevant information about a disadvantage of current microfluidic immobilization systems." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "None of the provided categories perfectly fit the given text. However, the closest category for the given sentence would be "Result," as it provides relevant information about the research topic and existing theories in relation to the minor differences observed for helium." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "The given text "6" does not provide any information to determine its classification in the concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The text does not fit into any of the provided concept categories. It seems to be describing a specific observation or result related to the introduction of deuterium into the ammonia molecule, but it does not fit neatly into any of the provided categories." => "Result"
WARNING:llms.metrics:Ignoring 900 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 832 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 931 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 521 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 990 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 658 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 656 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: 0.520, 0.680, 0.800
guideline_match_Motivation_Motivation: -0.400, -0.243, -0.071
guideline_match_Method_Background: 0.631, 0.750, 0.833
guideline_match_Result_Conclusion: -0.884, -0.768, -0.594
guideline_match_Conclusion_Method: nan, -1.000, nan
guideline_match: 0.132, 0.219, 0.303

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.007, 1.016
tokens_per_sentence: 1.086, 1.179, 1.331
tokens_per_sample: 1.139, 1.291, 1.534
fkgl_readability: 7.092, 7.443, 7.796

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.167, 1.667
tokens_diff: 23.100, 29.100, 34.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 16 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Result',
 'Method': 'Conclusion',
 'Motivation': 'Background',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that provides context, foundational knowledge, or '
  ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that provides contex ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text does not clearly fit into any of the provided concept categories. It appears to be a specific term or phrase rather than a sentence that provides context, empirical findings, reasons/objectives, key takeaways/implications, or research methods." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The text appears to be a scientific statement or observation, rather than fitting into one of the specific concept categories listed." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text. The sentence does not fit into any of the categories as it does not provide motivation, conclusion, background, method, or result of a research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories match the given text. The text does not fit into any of the categories of Motivation, Conclusion, Background, Method, or Result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fall into any of the concept categories provided. It seems to be a chemical compound description, including spectroscopic data and molecular weight information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "It is not possible to accurately classify the given text into one of the concept categories without any context or content." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "N/A" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above directly apply to the given text. This text appears to be part of a scientific explanation or equation, rather than a sentence that fits into one of the specified categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text given does not fit into any of the provided categories as it is incomplete and does not provide enough information to classify it accurately." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories fit the given sentence. The sentence does not provide motivation, conclusion, background, method, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the given categories are applicable to the text "6." This text does not provide any context, empirical findings, background reasons, method details, or research results." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 849 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 917 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 906 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 966 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 636 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 989 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 646 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 642 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.338, -0.192, -0.033
guideline_match_Motivation_Background: 0.181, 0.398, 0.590
guideline_match_Method_Result: 0.404, 0.574, 0.723
guideline_match_Result_Conclusion: -0.706, -0.412, -0.059
guideline_match_Conclusion_Method: -1.000, 0.000, 1.000
guideline_match: 0.016, 0.121, 0.220

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.007, 1.014
tokens_per_sentence: 1.095, 1.179, 1.321
tokens_per_sample: 1.153, 1.297, 1.543
fkgl_readability: 6.561, 7.023, 7.486

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 20.393, 27.000, 32.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 17 of 50:
{'Background': 'Result',
 'Conclusion': 'Method',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that presents the empirical findings, outcomes, '
 'o ... research is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Background: A sentence that presents the em ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "Unfortunately, without more context or information about the text, it is not possible to accurately classify it into one of the listed categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories directly apply to the text provided. The text seems to be a remark or comment rather than a scientific concept related to background, result, method, conclusion, or motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the categories listed above as it does not pertain to a scientific concept or research-related content." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sorry, but I'm not able to classify the provided text into one of the concept categories as it seems incomplete. Could you please provide more context or information?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. It does not fall under Background, Result, Method, Conclusion, or Motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the concept categories provided. It appears to be a statement about a chemical reaction rather than a description of empirical findings, results, methods, conclusion, or motivation of a research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "It is not possible to classify the text "6" into one of the concept categories listed above as it does not convey any information related to background, result, method, conclusion, or motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 915 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 925 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 786 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 481 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 654 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 650 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.600, 0.765, 0.882
guideline_match_Motivation_Motivation: -0.457, -0.300, -0.143
guideline_match_Method_Conclusion: -1.000, -0.973, -0.867
guideline_match_Result_Background: 0.841, 0.907, 0.953
guideline_match_Conclusion_Result: -1.000, -0.200, 0.600
guideline_match: 0.191, 0.276, 0.356

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.010
tokens_per_sentence: 1.063, 1.155, 1.331
tokens_per_sample: 1.097, 1.227, 1.473
fkgl_readability: 5.112, 5.527, 5.946

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 27.571, 32.429, 37.714
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 18 of 50:
{'Background': 'Method',
 'Conclusion': 'Background',
 'Method': 'Result',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 "inte ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Result: A sentence that summarizes the key  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided categories. It seems to be a statement or description related to a specific scientific concept or topic." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the categories listed above (Result, Motivation, Method, Conclusion, Background) are applicable to the text provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Without more context or specific information, it is not possible to classify the text into one of the categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Conclude" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not clearly fall into any of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories are applicable to the provided text. The text does not contain any information that can be classified into the given categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above directly apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided scientific concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories directly applies to the text provided. However, this text seems to fall into the "Background" category as it provides information about specific sections (3.2.1 and 3.2.2) which may contain details about the research methods, techniques, and procedures used in the study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are suitable for classifying the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Text: For the C __SB__ isomer, ca .

Category: Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None. The given text does not fit into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the given categories are applicable to the text "6" as it does not provide any information related to research, results, motivation, method, conclusion, or background." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 897 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 842 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 818 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 413 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 989 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 738 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 735 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.981, -0.942, -0.845
guideline_match_Motivation_Motivation: -0.214, -0.043, 0.129
guideline_match_Method_Background: 0.734, 0.835, 0.911
guideline_match_Result_Method: 0.692, 0.791, 0.868
guideline_match_Conclusion_Result: -0.500, 0.500, 1.000
guideline_match: 0.220, 0.298, 0.373

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.010
tokens_per_sentence: 1.095, 1.192, 1.358
tokens_per_sample: 1.127, 1.255, 1.493
fkgl_readability: 4.796, 5.241, 5.688

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 17.818, 23.182, 32.818
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 19 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Method',
 'Method': 'Conclusion',
 'Motivation': 'Background',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that summarizes the key takeaways, implications, '
 "inte ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that summarizes the key  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the listed concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fall into any of the specified concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text above does not fit into any of the concept categories provided. It appears to be a standalone statement that does not fall under the categories of Method, Background, Conclusion, Result, or Motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the given text. The text does not fall into any of the categories of Method, Background, Conclusion, Result, or Motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Implication/Interpretation" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "No specific category can be assigned to the given text as it does not fall into any of the provided categories. The text seems to be discussing a concept related to Hilbert subspaces and their size." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text, as it does not pertain to any specific scientific concept or research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "This text does not fit into any of the categories mentioned above as it does not provide a sentence that summarizes key takeaways, explains reasons or objectives, describes research methods or presents empirical findings. Therefore, it does not fall into any specific category." => "Method"
WARNING:llms.classifiers.models:Prediction "The given text does not provide enough information to be classified into any of the concept categories listed above. It appears to be incomplete or truncated." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The scientific concept in the given text is "state transition."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the given categories perfectly fit the provided text. However, if we have to classify it into one of the given categories, we can consider it as a possible Result, as it presents a comparison between the favorable and less favorable orientations of intramolecular hydrogen bonds." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the listed concept categories accurately describe the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information in the provided text to categorize it into one of the categories listed above. The text is descriptive in nature and does not fit into any specific scientific concept category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed (Method, Background, Conclusion, Result, Motivation) are applicable to the text "6" as it does not provide any relevant information to classify it into a scientific concept category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "The given text does not clearly fit into any of the concept categories listed above. It appears to be a specific reference (__REF__) and a mention of a specific emission related to the Δυ __SB__ = −1 asymmetric stretch bands of HCCO. It does not provide sufficient context to be classified into any of the categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None (the text does not fit into any of the provided categories)" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 752 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 956 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 888 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 297 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 986 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 639 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 636 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: 0.250, 0.371, 0.484
guideline_match_Motivation_Background: -0.636, -0.409, -0.091
guideline_match_Method_Conclusion: -0.946, -0.875, -0.768
guideline_match_Result_Result: 0.892, 0.939, 0.973
guideline_match_Conclusion_Method: nan, -1.000, nan
guideline_match: 0.283, 0.354, 0.422

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.007, 1.016
tokens_per_sentence: 1.133, 1.240, 1.422
tokens_per_sample: 1.196, 1.370, 1.662
fkgl_readability: 9.398, 9.943, 10.503

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.167, 1.667
tokens_diff: 19.500, 26.429, 34.929
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 20 of 50:
{'Background': 'Background',
 'Conclusion': 'Result',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that explains the reasons, objectives, or goals behind '
 ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that explains the reason ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Result'
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided categories. It is not related to the research method, motivation, result, background, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "The background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "There is no specific scientific concept mentioned in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information in the provided text to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories (Method, Motivation, Result, Background, Conclusion) can be applied to the given text "This is not insubstantial." as it does not pertain to scientific research or findings." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the provided text does not contain enough information to accurately classify it into one of the concept categories listed above. Can you please provide more context or information?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not fit into any of the concept categories listed above. It appears to be a specific scientific statement or observation rather than a sentence that fits into one of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept in the given text is "Method"." => "Method"
WARNING:llms.classifiers.models:Prediction "This text does not fall into any of the given categories as it does not contain information related to research goals, motivations, research methods, results, or background context." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fall into any of the categories listed above. It does not pertain to research methods, motivation, results, background, or conclusions." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "The given text "6" does not provide enough information to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 876 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 805 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 922 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 329 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 676 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 672 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.800, 0.867, 0.919
guideline_match_Motivation_Method: -0.710, -0.581, -0.419
guideline_match_Method_Result: 0.036, 0.179, 0.313
guideline_match_Result_Conclusion: -0.949, -0.846, -0.692
guideline_match_Conclusion_Motivation: nan, -1.000, nan
guideline_match: 0.115, 0.189, 0.261

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.005, 1.011
tokens_per_sentence: 1.080, 1.167, 1.323
tokens_per_sample: 1.119, 1.255, 1.491
fkgl_readability: 7.080, 7.360, 7.625

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 21.778, 28.333, 33.444
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 21 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Motivation',
 'Motivation': 'Method',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that presents the empirical findings, outcomes, '
 'o ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Background: A sentence that presents the em ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "None of the categories listed above accurately describe the provided text. The text appears to be discussing a specific method or technique used in a study." => "Method"
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not provide enough information to classify it into one of the categories mentioned above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "There is not enough information provided to classify the text into one of the categories listed above. The text does not contain empirical findings, explanations of research objectives or goals, context about the research topic or existing theories, a summary of key takeaways or implications, or descriptions of research methods or data collection processes." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories (Background, Method, Result, Conclusion, Motivation) seem to be a perfect fit for categorizing the given text. However, the closest category that fits the text would be "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The text does not fit into any of the categories mentioned." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None. The given text does not fit into any of the concept categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the concept categories provided. It does not pertain to empirical findings, research methods, background information, research results, or conclusions." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the categories listed above as it appears to be an incomplete sentence or fragment." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories (Background, Method, Result, Conclusion, Motivation) are applicable to the given text "6" as it does not contain any relevant information for classification." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 852 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 896 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 879 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 851 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 470 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 667 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 664 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: 0.514, 0.649, 0.757
guideline_match_Motivation_Method: -0.635, -0.481, -0.308
guideline_match_Method_Motivation: -0.554, -0.388, -0.207
guideline_match_Result_Background: 0.812, 0.906, 0.960
guideline_match_Conclusion_Conclusion: -0.250, 0.500, 1.000
guideline_match: 0.177, 0.260, 0.340

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.010
tokens_per_sentence: 1.063, 1.145, 1.307
tokens_per_sample: 1.088, 1.204, 1.418
fkgl_readability: 6.720, 7.103, 7.501

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 19.125, 25.500, 33.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 22 of 50:
{'Background': 'Method',
 'Conclusion': 'Conclusion',
 'Method': 'Motivation',
 'Motivation': 'Background',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not fit into any of the concept categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not contain enough information to determine the scientific concept it belongs to." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "The given text does not fall into any of the categories listed above. It does not provide information related to research methods, findings, conclusions, motivations, or background context." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "This text does not fit clearly into any of the provided categories. It appears to be describing a specific observation or result related to concentration decay near an injecting boundary." => "Result"
WARNING:llms.classifiers.models:Prediction "I'm sorry, but it seems like the given text is incomplete or not related to any specific scientific concept. Can you please provide more information or context?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories is directly applicable to this text. It does not fit into any of the categories of Conclusion, Background, Result, Method, or Motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately capture the concept described in the text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "There is not enough information provided to classify the text into one of the given categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 805 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 948 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 880 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 330 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 629 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 627 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: 0.159, 0.292, 0.426
guideline_match_Motivation_Method: -0.385, -0.115, 0.154
guideline_match_Method_Background: -0.300, -0.117, 0.067
guideline_match_Result_Result: 0.790, 0.858, 0.912
guideline_match_Conclusion_Conclusion: -0.250, 0.500, 1.000
guideline_match: 0.370, 0.439, 0.504

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.044, 1.106, 1.209
tokens_per_sample: 1.062, 1.155, 1.327
fkgl_readability: 8.405, 8.900, 9.409

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 16.714, 22.143, 29.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 23 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Method',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that explains the reasons, objectives, or goals behind '
 ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Result: A sentence that explains the reason ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above accurately classify the given text. The text does not fall into any of the defined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This specific text does not fit into any of the provided concept categories. It appears to be a numerical value related to a specific section or subsection in a scientific paper, providing data or information about a certain isomer." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the text provided does not contain enough information to determine its classification into one of the given categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is no clear scientific concept described in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the categories mentioned above directly apply to the given text. The text does not provide any information about reasons, objectives, goals, research methods, data collection processes, experimental design, background information, or research findings. Therefore, it cannot be classified into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly fit with the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories can accurately classify the given text. The text does not fit into any of the provided categories, as it does not pertain to the reasons, objectives, motivation, methods, background, or conclusions of the research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the categories listed above apply to the given text as it does not pertain to any aspect of scientific research or its results." => "Result"
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. It appears to be a specific statement or observation rather than a description of the reasons, methods, background, or conclusion of a research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not clearly fit into any of the concept categories provided. It is a factual statement about Laue diffraction and does not pertain to the reasons, methods, background, results, or conclusions of a research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Without any specific text provided, it is not possible to classify it into one of the categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the text "The reference cell was filled with matching buffer." This text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 828 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 881 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 944 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 375 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 988 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 718 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 715 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.872, 0.942, 0.977
guideline_match_Motivation_Result: -0.765, -0.647, -0.496
guideline_match_Method_Motivation: -0.429, -0.179, 0.071
guideline_match_Result_Background: 0.452, 0.556, 0.652
guideline_match_Conclusion_Conclusion: -0.750, 0.000, 0.750
guideline_match: 0.286, 0.360, 0.430

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.008, 1.017
tokens_per_sentence: 1.105, 1.202, 1.349
tokens_per_sample: 1.178, 1.356, 1.653
fkgl_readability: 2.766, 3.207, 3.670

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.143, 1.571
tokens_diff: 21.583, 29.667, 38.583
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 24 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Background',
 'Method': 'Result',
 'Motivation': 'Conclusion',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that presents the empiri ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "Observation" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above seem to be applicable to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the concept categories provided. It appears to be a statement related to the characteristics or performance of templates and gold substrates in a research context, rather than fitting into the specified categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fall into any of the given concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 866 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 906 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 838 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 908 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 516 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 666 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 666 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.896, -0.806, -0.687
guideline_match_Motivation_Background: 0.106, 0.319, 0.489
guideline_match_Method_Result: 0.654, 0.765, 0.852
guideline_match_Result_Method: 0.457, 0.630, 0.761
guideline_match_Conclusion_Motivation: nan, -1.000, nan
guideline_match: 0.120, 0.211, 0.298

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.014, 1.057, 1.153
tokens_per_sample: 1.022, 1.079, 1.265
fkgl_readability: 6.236, 6.668, 7.094

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000
tokens_diff: 11.500, 19.750, 35.750
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 25 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Method',
 'Method': 'Result',
 'Motivation': 'Background',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that presents the empiri ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the categories listed above. It seems to be a specific scientific concept related to the research being discussed, but it does not fit neatly into one of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories listed above. It seems to be a technical or scientific description related to a specific field or study, rather than a sentence that fits into one of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is no specific scientific concept mentioned in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the text provided does not contain enough information to be classified into one of the categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The concept in the given text is "Results."" => "Result"
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories (Method, Background, Conclusion, Motivation, Result) seem to be applicable to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories listed above. It does not provide information related to empirical findings, key takeaways, research methods, motivation, or research objectives/goals." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. It appears to be an incomplete sentence or phrase and does not convey information related to empirical findings, background, conclusion, motivation, or results." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the given text, as it does not pertain to any empirical findings, background information, research methods, or motivations/goals of the research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "The text "6" does not provide enough information to be classified into any of the categories listed above. It is not related to any specific concept or research context." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 802 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 938 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 975 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 819 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 530 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 679 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 676 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.394, -0.263, -0.121
guideline_match_Motivation_Result: -0.806, -0.645, -0.419
guideline_match_Method_Conclusion: -1.000, -0.920, -0.600
guideline_match_Result_Method: 0.812, 0.890, 0.945
guideline_match_Conclusion_Background: -1.000, -0.500, 0.500
guideline_match: 0.004, 0.094, 0.183

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.005, 1.011
tokens_per_sentence: 1.086, 1.183, 1.352
tokens_per_sample: 1.132, 1.280, 1.536
fkgl_readability: 3.262, 3.809, 4.365

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 23.440, 31.111, 36.667
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 26 of 50:
{'Background': 'Result',
 'Conclusion': 'Background',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that explains the re ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "There is not enough information provided in the text to classify it into one of the concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories accurately describe the given text. It does not provide motivation, background, conclusion, result, or method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above accurately describe the given text. The text appears to be a mathematical equation or formula, which does not fit into any of the concept categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "This text falls under the category of "Method" as it provides details about the research methods, techniques, procedures, and data collection processes used in the study. It includes information about the experimental design, data analysis, and materials or instruments utilized." => "Method"
WARNING:llms.classifiers.models:Prediction "There are multiple scientific concepts mentioned in the given text. Here is the classification of each concept into one of the categories listed above:

- Motivation: None present in the given text.
- Background: None present in the given text.
- Conclusion: None present in the given text.
- Result: None present in the given text.
- Method: The sentence describes the research method used in the study, specifically the fact that the occupation number is a function of energy or frequency and becomes a function of r due to the mode energy depending on r. Therefore, the category for this sentence is "Method."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "Unfortunately, based on the given text, it is not possible to classify it into any of the provided categories. The text does not contain enough information related to research, empirical findings, conclusions, results, or research methods to be categorized." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the provided categories directly apply to this sentence. However, if we were to choose the most relevant category, it would be "Conclusion" as it provides information about potential mechanisms for the observed stripe patterns." => "Conclusion"
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "It is difficult to classify the given text into one of the categories listed above as it does not pertain to any specific research context or contain enough information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories seem to be applicable to the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sorry, but I can't help with that request." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This sentence does not fit into any of the categories listed above. It does not provide motivation, background, conclusion, results, or methods for a research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not contain enough information to be classified into one of the categories listed. It appears to be incomplete." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "Comparison" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text "6" does not contain enough information to classify it into one of the listed categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 912 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 854 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 348 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 988 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 615 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 612 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.795, -0.659, -0.477
guideline_match_Motivation_Motivation: 0.057, 0.214, 0.371
guideline_match_Method_Method: 0.572, 0.667, 0.754
guideline_match_Result_Background: 0.329, 0.479, 0.616
guideline_match_Conclusion_Result: nan, 1.000, nan
guideline_match: 0.276, 0.350, 0.420

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.010, 1.033
tokens_per_sentence: 1.105, 1.200, 1.352
tokens_per_sample: 1.183, 1.382, 1.876
fkgl_readability: 6.098, 6.585, 7.091

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.667, 3.667
tokens_diff: 21.500, 31.833, 58.052
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 27 of 50:
{'Background': 'Background',
 'Conclusion': 'Method',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The concept in the given text is "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Conclusions" => "Conclusion"
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text is not sufficient to classify it into any of the provided categories. It appears to be incomplete or lacking relevant information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept in the given text is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Prediction "The given text does not fall into any of the categories listed above. It does not convey any scientific concept or information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "This text falls under the "Method" category." => "Method"
WARNING:llms.classifiers.models:Prediction "The provided text "6" does not provide any information or context that can be classified into the concept categories given. Therefore, it cannot be classified into any of the categories listed." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 885 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 933 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 251 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 603 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 603 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.496, 0.600, 0.689
guideline_match_Motivation_Method: -0.774, -0.652, -0.496
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Result: 0.580, 0.668, 0.749
guideline_match_Conclusion_Motivation: nan, -1.000, nan
guideline_match: 0.215, 0.287, 0.354

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.011, 1.042, 1.120
tokens_per_sample: 1.023, 1.086, 1.249
fkgl_readability: 5.305, 5.687, 6.056

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 24.333, 28.667, 36.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 28 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Background',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Conclusion." => "Conclusion"
WARNING:llms.classifiers.models:Prediction "The text could be classified as "Conclusion" as it summarizes the implications and insights derived from the study's results about the occurrence and behavior of aggregates in relation to electron transfer and relaxation processes." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The provided text does not fit into any of the concept categories listed. It appears to be a scientific statement describing a compound or structure, but it does not fall into the categories of Conclusion, Motivation, Background, Result, or Method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Conception: Result" => "Result"
WARNING:llms.classifiers.models:Prediction "The text provided does not contain enough information to be classified into any of the concept categories listed above. It appears to be a placeholder or reference code rather than content that can be categorized." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "N/A (The given text does not pertain to any specific scientific concept.)" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the listed categories. It appears to be incomplete or missing relevant information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There isn't enough information in the given text to classify it into one of the categories listed." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The text "The original spectra contain interference fringes from different optical elements." falls under the "Result" category." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the given categories directly apply to the provided text. The text does not provide a conclusion, motivation, background, result, or method for a research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "None of the given categories perfectly match the provided text. The text seems to describe a scientific concept related to the acidity of certain compounds due to charge delocalization. It does not fit into any of the given categories directly." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the text "6." It does not contain any information that can be classified into one of those categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the concept categories listed above as it is a statement of scientific information rather than a specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 852 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 927 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 200 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 990 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 588 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 586 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.095, 0.068, 0.230
guideline_match_Motivation_Background: 0.068, 0.288, 0.507
guideline_match_Method_Method: 0.435, 0.543, 0.638
guideline_match_Result_Result: 0.702, 0.783, 0.844
guideline_match_Conclusion_Conclusion: 0.000, 0.750, 1.000
guideline_match: 0.460, 0.522, 0.578

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.007, 1.016
tokens_per_sentence: 1.091, 1.189, 1.357
tokens_per_sample: 1.147, 1.303, 1.569
fkgl_readability: 7.506, 8.001, 8.495

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.167, 1.667
tokens_diff: 24.100, 30.300, 36.300
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 29 of 50:
{'Background': 'Background',
 'Conclusion': 'Result',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that explains the re ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "Without further context, it is not possible to classify the given text into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately fit the provided text. The text does not pertain to motivation, conclusion, method, background, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories are applicable to the given text. The text does not pertain to any scientific concept, motivation, conclusion, method, background, or result." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories (Motivation, Conclusion, Method, Background, Result) accurately apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories (Motivation, Conclusion, Method, Background, Result) directly applies to the text provided. The text seems to describe a specific finding or observation, but it does not fit neatly into any of the predefined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is no clear category for the given text as it does not fit into any of the concept categories provided (Motivation, Conclusion, Method, Background, or Result)." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the categories listed above. It appears to be a statement related to a specific scientific concept, but without further context, it cannot be classified into one of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not provide any information that can be classified into one of the concept categories listed above. It is an incomplete sentence or unrelated text that does not pertain to a specific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 845 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 156 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 615 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 610 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.667, 0.756, 0.830
guideline_match_Motivation_Motivation: -0.629, -0.486, -0.329
guideline_match_Method_Method: 0.565, 0.659, 0.746
guideline_match_Result_Conclusion: -0.923, -0.858, -0.755
guideline_match_Conclusion_Result: -1.000, -0.333, 1.000
guideline_match: 0.154, 0.218, 0.284

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.005, 1.011
tokens_per_sentence: 1.076, 1.166, 1.332
tokens_per_sample: 1.119, 1.261, 1.526
fkgl_readability: 4.484, 4.899, 5.314

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 26.875, 32.625, 39.125
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 30 of 50:
{'Background': 'Method',
 'Conclusion': 'Background',
 'Method': 'Motivation',
 'Motivation': 'Result',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 "inte ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Result: A sentence that summarizes the key  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Background'
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately fit the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the listed categories. It is providing specific information about the intramolecular bending vibrations of ammonia and does not fall into the categories of Result, Conclusion, Motivation, Background, or Method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the categories mentioned above fit the provided text. The sentence does not pertain to research findings, context, empirical observations, research methods, or research objectives." => "Method"
WARNING:llms.classifiers.models:Prediction "No specific scientific concept is evident in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the concept categories listed above. It appears to contain technical terms and equations related to a specific scientific study or field, but it does not specifically address background, method, motivation, result, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The scientific concept in the given text is "Resonances."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not provide enough information to classify it into any of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the categories provided. It appears to be a standalone sentence without any clear context or relevance to a specific research topic or findings." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories (Result, Conclusion, Motivation, Background, Method) are applicable to the given text. It does not provide any empirical findings, context, research methods, or goals." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the given text. The text does not pertain to any scientific concept or research category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories listed above and does not pertain to a specific scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The text does not fit into any of the defined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately fit the text provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "Sorry, but I can't classify the text "6" into any of the categories provided. Is there something else I can help you with?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "- Background" => "Background"
WARNING:llms.metrics:Ignoring 937 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 920 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 784 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 858 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 492 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 987 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 711 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 708 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.841, -0.683, -0.460
guideline_match_Motivation_Method: -0.850, -0.725, -0.550
guideline_match_Method_Background: 0.741, 0.824, 0.889
guideline_match_Result_Motivation: -0.408, -0.254, -0.099
guideline_match_Conclusion_Result: -0.143, 0.714, 1.000
guideline_match: 0.004, 0.091, 0.177

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.007, 1.014
tokens_per_sentence: 1.105, 1.196, 1.339
tokens_per_sample: 1.162, 1.317, 1.572
fkgl_readability: 8.813, 9.165, 9.531

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 18.462, 24.385, 31.846
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 31 of 50:
{'Background': 'Background',
 'Conclusion': 'Motivation',
 'Method': 'Method',
 'Motivation': 'Conclusion',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that presents the empirical findings, outcomes, '
 'obser ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Result: A sentence that presents the empiri ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The given text does not clearly fit into any of the concept categories provided. It appears to be describing a specific calculation or calculation process rather than presenting empirical findings, explaining reasons or objectives, summarizing key takeaways, providing context, or describing research methods." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "Insufficient information. The provided text does not contain enough context or content to be classified into any specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the provided categories accurately classify the given text. However, if we were to classify it based on the closest available category, it could be categorized as "Method" since it discusses the approximation of ρ using fitting functions." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "None of the provided categories would be suitable for classifying the given text as it does not pertain to scientific concepts, empirical findings, research methods, or contextual information." => "Method"
WARNING:llms.classifiers.models:Prediction "The provided text does not provide enough information to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the text provided. The text appears to be discussing a hypothetical scenario or prediction based on certain conditions and does not fit into any specific categories such as Result, Conclusion, Motivation, Background, or Method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information provided in the text to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 907 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 63 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 596 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 595 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.533, 0.630, 0.719
guideline_match_Motivation_Conclusion: -1.000, -0.957, -0.849
guideline_match_Method_Method: 0.341, 0.449, 0.543
guideline_match_Result_Result: 0.647, 0.729, 0.797
guideline_match_Conclusion_Motivation: nan, -1.000, nan
guideline_match: 0.387, 0.445, 0.501

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.002, 1.007
tokens_per_sentence: 1.020, 1.071, 1.188
tokens_per_sample: 1.038, 1.105, 1.309
fkgl_readability: 6.007, 6.401, 6.783

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 19.500, 26.250, 39.500
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 32 of 50:
{'Background': 'Background',
 'Conclusion': 'Motivation',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that describes the research methods, techniques, '
 'proc ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that describes the resea ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the listed concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories apply to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above directly apply to the given text. The text does not fit into any of the categories related to research methods, background information, conclusion, motivation, or results." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "None of the given categories fit the given text. The text seems to be a technical notation or equation rather than a description of research methods, background, conclusions, motivation, or results." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above fully capture the scientific concept described in the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the provided text is incomplete and does not contain enough information to classify it into one of the categories listed above. Please provide a more complete text or specify a specific scientific concept to classify." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the text "6" as it is not related to a scientific concept." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text does not fit into any of the categories provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 881 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 880 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 213 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 618 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 616 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.630, 0.719, 0.793
guideline_match_Motivation_Conclusion: -0.933, -0.866, -0.748
guideline_match_Method_Method: 0.500, 0.601, 0.688
guideline_match_Result_Motivation: -0.883, -0.800, -0.667
guideline_match_Conclusion_Result: nan, -1.000, nan
guideline_match: 0.133, 0.202, 0.271

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.066, 1.140, 1.266
tokens_per_sample: 1.089, 1.197, 1.401
fkgl_readability: 5.004, 5.414, 5.827

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 15.444, 21.889, 30.111
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 33 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that provides context, foundational knowledge, or '
 'rel ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Result: A sentence that provides context, f ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "None of the categories listed above apply to the given text. The given text does not provide any context, motivation, method, background, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. It appears to be discussing specific scientific information or calculations related to a research topic, but it does not clearly fit into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately describe the text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not provide enough information for classification into any of the concept categories mentioned above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text. It does not fit into the categories of Result, Motivation, Method, Background, or Conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "N/A" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not provide enough information to classify it into one of the listed categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above (Result, Motivation, Method, Background, Conclusion) are applicable to the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the concept categories mentioned above. It appears to be a statement or description related to a specific research topic, but it does not belong to the Result, Motivation, Method, Background, or Conclusion categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories (Result, Motivation, Method, Background, Conclusion) are applicable to the text "6" as it does not fit the criteria of any of these categories. It appears to be a standalone number without any context or meaning in the scientific context." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the given categories directly apply to the text "We elaborate more about this issue in Section IV." It does not provide context, motivation, method, background, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 893 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 755 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 224 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 990 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 661 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 655 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: -0.421, -0.234, -0.047
guideline_match_Motivation_Motivation: 0.243, 0.400, 0.543
guideline_match_Method_Method: 0.558, 0.652, 0.732
guideline_match_Result_Background: 0.722, 0.804, 0.869
guideline_match_Conclusion_Conclusion: -0.750, 0.000, 0.750
guideline_match: 0.466, 0.526, 0.588

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.013
tokens_per_sentence: 1.093, 1.187, 1.342
tokens_per_sample: 1.148, 1.308, 1.587
fkgl_readability: 6.067, 6.534, 6.996

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 23.100, 30.800, 39.500
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 34 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Method',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that explains the re ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "None of the given categories (Motivation, Conclusion, Background, Result, Method) accurately classify the provided text. The text seems to be a specific detail related to a scientific experiment or measurement, rather than fitting into any of the predefined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately categorize this text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "This text can be classified under the category "Method"." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the categories mentioned above accurately describe the given text. The text does not fit into any of the provided categories as it does not pertain to motivation, conclusion, background, result, or method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the given categories directly apply to the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sorry, I am unable to classify the given text into any of the concept categories listed above as it does not provide any meaningful information or context." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not contain enough information to classify it into one of the concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately apply to the given text as it does not pertain to any specific scientific concept or research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sorry, but I'm unable to classify the text provided into one of the concept categories listed above as it seems to be incomplete. Could you please provide more context or information?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 846 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 977 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 384 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 612 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 610 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.714, 0.818, 0.896
guideline_match_Motivation_Motivation: -0.443, -0.286, -0.129
guideline_match_Method_Conclusion: -1.000, -0.913, -0.565
guideline_match_Result_Result: 0.437, 0.539, 0.627
guideline_match_Conclusion_Background: -1.000, 0.000, 1.000
guideline_match: 0.286, 0.364, 0.435

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.009
tokens_per_sentence: 1.066, 1.149, 1.292
tokens_per_sample: 1.091, 1.210, 1.440
fkgl_readability: 3.081, 3.529, 3.987

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 18.125, 26.250, 35.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 35 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Result',
 'Motivation': 'Method',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "None of the categories listed above seem to accurately fit the provided text. The text does not summarize key takeaways or implications, explain reasons or objectives, provide background information, describe research methods or techniques, or present empirical findings or outcomes. Therefore, it does not fall into any of the given categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Based on the given text, it is not possible to classify it into one of the concept categories listed above. The text appears to be incomplete or unrelated to any specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately fit the provided text. The text appears to contain a mathematical expression or equation in a scientific context. Therefore, it does not fall into any of the concept categories listed." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately fit the provided text. The text does not discuss any conclusions, results, background, motivation, or methods of research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the listed categories apply to the given text as it does not pertain to any scientific concept or research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The text provided does not contain enough information to be classified into one of the given categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above (Conclusion, Result, Background, Motivation, Method) fully capture the concept presented in the given text. This text provides an explanation about the possible reasons behind the changes in the acoustic properties observed during the formation of CdS nanoparticles." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the given categories explicitly match the text provided. However, if we consider the closest match, the text can be categorized as a "Method" as it presents an observation or outcome of the research related to the robustness and adherence of the templates to gold substrates." => "Method"
WARNING:llms.classifiers.models:Prediction "I'm sorry, the text "6" does not provide enough information to classify it into one of the concept categories listed above. Can you please provide more context or a complete sentence?" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 905 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 873 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 810 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 310 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 648 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 646 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.696, 0.778, 0.844
guideline_match_Motivation_Result: -0.916, -0.832, -0.684
guideline_match_Method_Motivation: -0.307, -0.134, 0.039
guideline_match_Result_Method: 0.421, 0.547, 0.663
guideline_match_Conclusion_Conclusion: -0.250, 0.500, 1.000
guideline_match: 0.249, 0.322, 0.388

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.003, 1.008, 1.017
tokens_per_sentence: 1.063, 1.141, 1.274
tokens_per_sample: 1.125, 1.284, 1.565
fkgl_readability: 5.692, 6.168, 6.639

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.333, 1.833
tokens_diff: 27.000, 35.500, 45.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 36 of 50:
{'Background': 'Background',
 'Conclusion': 'Method',
 'Method': 'Result',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Method: A sentence that presents the empiri ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Finding/Result" => "Result"
WARNING:llms.classifiers.models:Prediction "The text provided does not fit into any of the concept categories listed. It appears to be a scientific discussion containing specific terms and symbols related to a chemical reaction or process. It does not fall neatly into any of the predefined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Without further context, it is difficult to classify the text into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The scientific concept in the given text cannot be classified into any of the categories mentioned." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information in the text to classify it into one of the listed concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text, as it does not pertain to empirical findings, research motivations, research methods, background information, or research results. Therefore, the text does not fall under any of the concept categories mentioned." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The text appears to be related to a specific calculation or comparison, rather than a concept category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Background." => "Background"
WARNING:llms.classifiers.models:Prediction "No category is applicable to the given text as it does not relate to any research methods, motivation, conclusion, background, or results." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the text "6." It is not a sentence that fits into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Consequently, the given text does not fit into any of the categories provided. It appears to be a partial sentence mentioning a figure in a scientific paper." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 935 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 879 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 402 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 627 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 626 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.570, 0.667, 0.748
guideline_match_Motivation_Motivation: -0.557, -0.414, -0.257
guideline_match_Method_Conclusion: -1.000, -0.969, -0.846
guideline_match_Result_Method: 0.372, 0.537, 0.669
guideline_match_Conclusion_Result: -1.000, 0.000, 1.000
guideline_match: 0.130, 0.207, 0.288

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.015
tokens_per_sentence: 1.075, 1.160, 1.300
tokens_per_sample: 1.120, 1.260, 1.506
fkgl_readability: 4.646, 5.063, 5.489

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.200, 1.800
tokens_diff: 23.111, 28.889, 36.778
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 37 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Background',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Motivation: A sentence that explains the re ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "None of the given categories are applicable to this text as it does not fit into any of the descriptions provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. The text appears to be a statement related to quantum mechanics or wave functions, but it does not clearly fall into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above fit this specific text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Not enough information is provided in the text to classify it into one of the concept categories listed. It appears to be a standalone statement that does not fit into any specific category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Results" => "Result"
WARNING:llms.classifiers.models:Prediction "Being unable to determine the specific content of the text provided, it is not possible to classify it into one of the given concept categories. Please provide a more complete sentence or text for classification." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories mentioned in the prompt perfectly captures the concept presented in the text. The text does not fit into the categories of Motivation, Background, Result, Method, or Conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The provided text does not fit into any of the listed categories. It does not provide motivation, background, results, methods, or a conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories seem to fit the given text. The text does not fall into any specific category as it is a statement presenting a hypothesis or possibility rather than discussing motivations, results, methods, background, or conclusions." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above apply to the given text. The given text does not fit into any of the categories related to motivation, background, result, method, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories seem to directly apply to the provided text since it is not related to research, methods, results, or conclusions." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The concept mentioned in the text is:
- Background" => "Background"
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text. The sentence does not involve motivation, background, result, method, or conclusion. It appears to be a standalone statement rather than a part of a scientific research article." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fall under any of the provided concept categories. It appears to be a technical expression related to electrons in a vacuum." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given concept categories directly apply to the provided text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept in the text is "Result"." => "Result"
WARNING:llms.classifiers.models:Prediction "Apologies, but I'm unable to assist." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories clearly fit this text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The provided text does not fit into any of the categories mentioned." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text "6" does not provide enough information to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 849 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 133 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 982 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 608 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 602 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -0.974, -0.934, -0.854
guideline_match_Motivation_Motivation: -0.186, -0.014, 0.157
guideline_match_Method_Method: 0.630, 0.725, 0.797
guideline_match_Result_Result: 0.742, 0.817, 0.878
guideline_match_Conclusion_Background: -1.000, -0.600, 0.600
guideline_match: 0.276, 0.340, 0.403

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.005, 1.010, 1.019
tokens_per_sentence: 1.162, 1.275, 1.448
tokens_per_sample: 1.256, 1.450, 1.747
fkgl_readability: 4.865, 5.326, 5.794

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.111, 1.444
tokens_diff: 18.500, 25.000, 30.944
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 38 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or '
  ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Background: A sentence that provides contex ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly applies to the given text. The text does not involve background information, results, methods, motivation, or a conclusion. Therefore, it cannot be classified into any of the specified categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not fit into any of the provided concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately fit the text "This perspective will highlight just a few of these last ones." It does not provide background information, present results, describe research methods, explain motivation, or provide a conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not clearly fall into any of the concept categories provided. It appears to be a partial statement or fragment, rather than a sentence that fits into one of the defined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories (Background, Result, Method, Motivation, Conclusion) accurately describes the concept presented in the text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the text provided. The text does not fit into any of the categories of background, result, method, motivation, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "The text "6" does not provide enough information to be classified into one of the categories listed above. It appears to be a numerical value or a fragment of a larger sentence." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 11 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 574 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 570 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.289, 0.400, 0.504
guideline_match_Motivation_Motivation: 0.157, 0.329, 0.471
guideline_match_Method_Method: 0.768, 0.841, 0.899
guideline_match_Result_Result: 0.539, 0.634, 0.715
guideline_match_Conclusion_Conclusion: -0.750, 0.000, 0.750
guideline_match: 0.525, 0.579, 0.628

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.015
tokens_per_sentence: 1.052, 1.124, 1.256
tokens_per_sample: 1.093, 1.229, 1.478
fkgl_readability: 5.282, 5.762, 6.239

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.200, 1.800
tokens_diff: 24.571, 32.714, 38.714
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 39 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Motivation',
 'Motivation': 'Method',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "None of the categories listed above are applicable to the given text as it doesn't fit into any of them." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not fit into any of the concept categories provided. It appears to be a statement or description without any clear connection to a specific research topic, background, method, result, or conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the provided categories directly apply to the given text. However, if we were to interpret the text as part of a research paper, it could potentially fall under the "Background" category as it provides information about the models being compared." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the provided sentences fit into any of the given concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "It is not possible to categorize the given text into one of the concept categories listed above because it does not provide any information related to conclusions, results, background, method, or motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly apply to the given text. The text does not pertain to a conclusion, result, background, method, or motivation of a scientific study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text. The text does not fit into any of the mentioned categories as it does not pertain to a conclusion, result, background, method, or motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above directly apply to the given text "This is not insubstantial." It does not relate to conclusions, results, background, methods, or motivation of a research study. It appears to be a statement unrelated to scientific concepts." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately classify the provided text. The text appears to be a formula or equation related to electron behavior in a vacuum." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the given categories perfectly match the provided text. However, the closest category that can be assigned to this text is "Result" as it discusses an empirical finding or observation related to the research." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Motivation." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "The scientific concept described in the text is "Background."" => "Background"
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 901 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 838 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 705 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 166 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 593 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 588 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.481, 0.585, 0.674
guideline_match_Motivation_Method: -0.960, -0.899, -0.778
guideline_match_Method_Motivation: -0.457, -0.321, -0.173
guideline_match_Result_Result: 0.722, 0.797, 0.858
guideline_match_Conclusion_Conclusion: 0.000, 0.750, 1.000
guideline_match: 0.245, 0.309, 0.374

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.015
tokens_per_sentence: 1.069, 1.154, 1.315
tokens_per_sample: 1.114, 1.260, 1.522
fkgl_readability: 8.147, 8.526, 8.911

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.200, 1.800
tokens_diff: 24.125, 32.500, 39.250
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 40 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Result',
 'Motivation': 'Motivation',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Conclusion: A sentence that summarizes the  ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "None of the categories listed above perfectly match the given text. However, if we were to classify it based on the closest fit, it would fall under "Method" or "Result" as it contains information related to the research findings and the techniques used in the study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "There is not enough information in the given text to classify it into one of the listed categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories seem to fit the provided text. The text appears to be discussing a scientific concept related to orbital configurations and their energetic proximity. Therefore, a new category may be needed to classify this text, such as "Scientific Concept" or "Orbital Configuration."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "Unfortunately, the given text does not provide enough information for me to classify it into one of the concept categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the concept categories provided. It does not provide a conclusion, background information, motivation, result, or method-related information." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above can be applied to the given text. The text does not pertain to a scientific concept or research study." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories apply to this text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above accurately describe the text "This is not insubstantial." The text does not fall into any of the provided scientific concept categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "This text does not belong to any of the concept categories listed above. It appears to be an incomplete sentence fragment." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided concept categories accurately capture the content of the given text. The text appears to be discussing a chemical reaction or process, rather than encompassing any of the listed categories such as Conclusion, Background, Motivation, Result, or Method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The given text does not fit into any of the categories provided as it does not pertain to background, motivation, conclusion, result, or method." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above can accurately classify the text "6" as it does not fall into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the listed categories apply to the given text. The text provided does not provide a conclusion, background information, motivation, results, or methods. It is simply a statement referring to a section in the document." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 860 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 958 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 913 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 453 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 987 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 606 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 603 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -0.052, 0.067, 0.185
guideline_match_Motivation_Motivation: 0.086, 0.257, 0.414
guideline_match_Method_Result: 0.381, 0.667, 0.857
guideline_match_Result_Method: 0.609, 0.770, 0.885
guideline_match_Conclusion_Conclusion: -0.250, 0.500, 1.000
guideline_match: 0.196, 0.280, 0.360

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.005, 1.011, 1.021
tokens_per_sentence: 1.121, 1.226, 1.390
tokens_per_sample: 1.223, 1.418, 1.738
fkgl_readability: 4.668, 5.159, 5.666

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.222, 1.556
tokens_diff: 25.308, 32.154, 39.462
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 41 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating gpt-3.5-turbo-0613 on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.OpenAIClassifier'>
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 315.317,
 'mean_truncation': -3506.728,
 'total_tokens': 315317,
 'total_truncation': -3506728}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that explains the reasons, objectives, or goals behind '
 ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{}
INFO:llms.models.base:Generation kwargs:
{'max_tokens': 256, 'memoizer_ignore_cache': False}
INFO:llms.models.base:Model input:
[{'content': 'Consider the following concept categories:\n'
             '\n'
             '- Result: A sentence that explains the reason ...  '
             'MS analysis of both the unmodified and modified peptide(s).',
  'role': 'user'},
 {'content': 'Scientific concept:', 'role': 'user'}]
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "This text does not fit into any of the provided concept categories. It appears to be describing a scientific concept related to the dissociation of ethylamine molecules in an aqueous solution, but it does not fit neatly into any of the provided categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "None of the given categories perfectly fit the provided text. However, if we have to assign a category, it can be classified as "Background" because it provides some descriptive information about the data being referred to." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the provided categories accurately classify the given text. The text does not fit into any of the categories as it does not provide reasons, objectives, goals, empirical findings, research methods, background information, or summarize key takeaways." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the provided categories fully apply to the given text. The text does not fit into the categories of Result, Motivation, Method, Background, or Conclusion." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "This text can be classified under the "Background" category." => "Background"
WARNING:llms.classifiers.models:Prediction "None of the provided categories directly applies to the given text. The sentence does not fit into any of the categories as it does not discuss reasons, objectives, goals, empirical findings, research methods, background information, or conclusions." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result." => "Result"
WARNING:llms.classifiers.models:Prediction "None of the listed categories accurately describe the text provided. The text appears to be discussing a specific scientific concept related to the transport of NaCl and the solid angles involved." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories accurately describe the text provided." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the given categories directly apply to the text "This is not insubstantial." It does not fit into any of the defined categories." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "The given text does not fit into any of the categories listed above." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "None of the categories listed above seem applicable to the text "6" as it does not provide any information or context related to research, motivation, methods, background, or conclusions." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 730 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 867 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 775 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 88 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 666 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 664 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.756, 0.830, 0.889
guideline_match_Motivation_Result: -0.774, -0.654, -0.519
guideline_match_Method_Method: 0.507, 0.609, 0.696
guideline_match_Result_Motivation: -0.511, -0.396, -0.271
guideline_match_Conclusion_Conclusion: -0.750, 0.000, 0.750
guideline_match: 0.173, 0.237, 0.298

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.002, 1.006, 1.013
tokens_per_sentence: 1.078, 1.167, 1.330
tokens_per_sample: 1.129, 1.282, 1.559
fkgl_readability: 5.251, 5.678, 6.109

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 22.111, 31.333, 38.333
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:No permutations remaining. Exiting loop.
INFO:__main__:Correlation with permutation_edit_distance:
permutation_edit_distance      1.000000
permutation_rouge1_distance    0.993481
permutation_rouge2_distance    0.998266
accuracy                            NaN
Name: permutation_edit_distance, dtype: float64
INFO:__main__:Correlation with permutation_rouge1_distance:
permutation_edit_distance      0.993481
permutation_rouge1_distance    1.000000
permutation_rouge2_distance    0.995893
accuracy                            NaN
Name: permutation_rouge1_distance, dtype: float64
INFO:__main__:Correlation with permutation_rouge2_distance:
permutation_edit_distance      0.998266
permutation_rouge1_distance    0.995893
permutation_rouge2_distance    1.000000
accuracy                            NaN
Name: permutation_rouge2_distance, dtype: float64
INFO:__main__:Permutation metric counts:
{0.0: 1, 0.4: 10, 0.6: 10, 0.8: 10, 1.0: 10}
