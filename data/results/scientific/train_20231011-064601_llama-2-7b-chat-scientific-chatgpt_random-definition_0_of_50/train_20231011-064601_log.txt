INFO:__main__:Processing label permutation 0 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or '
  ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text provided can be classified into the following scientific concept category:
Method: The text describes the research methods used in the study, including the experimental design, data analysis, and materials and instruments used. The categories include details about the methods employed, such as the solvent used (CDCl2), the temperature and pressure conditions, and the analytical techniques used (1H and 13C NMR spectroscopy)." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Background: Davis et al.'s work." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: __REF__" => "Background"
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 711 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 711 null score values in confidence interval computation
INFO:llms.metrics:classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 2.783, 3.163, 3.544

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 1 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Result',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that provides context, foundational knowledge, or '
 'rel ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that provides context, foundational knowledge, or '
  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "The text provided can be classified into the following scientific concept category:
Result:
The text describes the experimental methods, techniques, and data collection processes used in the study, including the experimental design, data analysis, and materials or instruments used. The text provides empirical findings, outcomes, observations, and data generated by the research, including quantitative and qualitative results, statistical analyses, and tables and figures." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.metrics:Ignoring 572 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 957 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 524 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 760 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 759 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.897, 0.935, 0.963
guideline_match_Motivation_Background: -1.000, -0.500, 0.500
guideline_match_Method_Result: -0.256, 0.023, 0.302

> guideline_match_Result_Motivation:

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: 0.790, 0.840, 0.887

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.000, 1.038, 1.228
tokens_per_sample: 1.000, 1.077, 1.462
fkgl_readability: -1.595, -1.321, -1.012

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 77.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 2 of 50:
{'Background': 'Result',
 'Conclusion': 'Background',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that provides context, foundational knowledge, or '
  ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that provides context, foundational knowledge, or ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.metrics:Ignoring 921 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 615 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 528 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 718 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 718 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: 0.165, 0.392, 0.570

> guideline_match_Motivation_Method:
mean: -1.000
guideline_match_Method_Result: -0.990, -0.974, -0.943
guideline_match_Result_Background: -0.143, 0.714, 1.000

> guideline_match_Conclusion_Motivation:
guideline_match: -0.780, -0.720, -0.653

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 8.510, 8.795, 9.091

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 3 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Method',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that describes the research methods, techniques, '
 ' ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that describes the research methods, techniques,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: ___Method___" => "Method"
WARNING:llms.metrics:Ignoring 484 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 992 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 465 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 779 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 779 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.888, 0.926, 0.953
guideline_match_Motivation_Background: -1.000, 0.333, 1.000
guideline_match_Method_Motivation: -1.000, -0.750, 0.000
guideline_match_Result_Result: nan, 1.000, nan

> guideline_match_Conclusion_Conclusion:
mean: -1.000
guideline_match: 0.854, 0.895, 0.929

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: -2.775, -2.550, -2.278

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 4 of 50:
{'Background': 'Background',
 'Conclusion': 'Method',
 'Method': 'Conclusion',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or '
  ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: __REF__" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: Perdew, Burke and Ernzerhof's 1996 exchange and correlation functional." => "Background"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 634 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 82 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 747 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 747 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.948, 0.974, 0.989
guideline_match_Motivation_Motivation: -0.333, 0.667, 1.000
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Result: -1.000, -0.429, 0.429

> guideline_match_Conclusion_Method:
guideline_match: 0.109, 0.174, 0.237

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 7.351, 7.589, 7.803

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 5 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Method',
 'Method': 'Result',
 'Motivation': 'Background',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 "inte ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 " ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the findings related to the role of lipid rafts in diseases, indicating that they may play a central role in various diseases such as virus infections, Alzheimer's disease, and prion diseases. This suggests future research directions and reiterates the study's contributions to the field. Therefore, the category "Result" is the most appropriate classification for the text." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The category "Result" is the most appropriate classification for the given text." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text you provided suggests that the Ginzburg temperature is a determining factor in the crossover, which is a scientific concept in the field of physics. Therefore, the category that best fits the text is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the key takeaways, implications, interpretations, or insights derived from the study's results, specifically the C __SB__ isomer." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the antitumor antibiotics, Bleomycins (BLMs), and their mechanism of action, which is to cleave DNA in an oxidative manner. It also mentions their clinical use for the treatment of specific types of cancer, including squamous cell and malignant lymphomas. This information summarizes the key findings and implications of the study, highlighting the significance of the research and providing context for future studies. Therefore, the category is "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, I would classify it under the category of "Scientific Concept."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the potential applications of CdS nanoparticles, which is the main result of the research. It highlights the exciting applications of these nanoparticles and the attention they have received in the scientific community." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text describes the key findings of the study, specifically the relationship between concentration and the shape transition of molecules, and the role of ionic strength in inducing these transitions. This information is relevant to the field of chemistry and is a significant contribution to understanding the behavior of molecules in various environments." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
Scientific concept: __REF__" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the research findings, specifically the classification of xylanases based on amino acid sequence similarities. It highlights the key takeaways from the study, including the fact that the majority of xylanases are members of families 10 and 11 of the glycosyl hydrolases. This category is the most appropriate for the given text." => "Result"
WARNING:llms.metrics:Ignoring 503 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 786 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 286 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 684 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 684 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.799, -0.742, -0.682
guideline_match_Motivation_Background: nan, -1.000, nan
guideline_match_Method_Conclusion: nan, -1.000, nan

> guideline_match_Result_Method:

> guideline_match_Conclusion_Result:
mean: -1.000
guideline_match: -0.860, -0.821, -0.773

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.006, 1.022, 1.066
tokens_per_sample: 1.012, 1.047, 1.139
fkgl_readability: 5.654, 6.075, 6.480

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 13.000, 15.667, 20.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 6 of 50:
{'Background': 'Method',
 'Conclusion': 'Background',
 'Method': 'Result',
 'Motivation': 'Conclusion',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'o ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Method: __XREF__COMPOUND" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "Method: The text describes the empirical findings and research results, specifically the stability of ground state alkali atoms on surfaces of carbon or metal oxide. It includes quantitative and qualitative results, statistical analyses, and other information related to the research findings." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method: D00(NH) = (31 000 ± 500) cm." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: These include integration of electrophoretic product sizing on a monolithic device, as well as optimization of conditions to provide faster PCR (under 7 minutes), single-molecule detection, real-time applications, and multiplexing." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text can be classified into the following scientific concept category:
Method: The text describes the experimental design, data collection processes, and statistical analyses used in the study. It includes details about the instrumentation, experimental conditions, and data analysis techniques employed in the research." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: Smith and Martel summarized literature data for K __SB__ equal to 63 and 2.8 at ionic strengths of solutions equal to 3.0 and 0.0 (298 K), respectively." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text describes the limitations of a specific research technique (conventional gas-phase IR spectroscopy) when applied to the study of glycine, which is prone to degradation due to its low thermal stability. Therefore, it falls under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Prediction "Method

The text provides information about the results of the research, specifically the rate coefficients and the error range of the reported values. Therefore, it belongs to the category of "Result"." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Prediction "Method: The text provides information about the empirical findings and research results, specifically the stability of the Pitzer salt compound." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text describes the research method used in the study, specifically the technique used to deposit silver from a low cyanide plating bath using pulse plating. Therefore, it falls under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text describes the empirical findings, observations, and data generated by the research, specifically the origin of a particular behavior in a supercritical fluid. It belongs to the "Method" category." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: Spirolides B  __XREF__COMPOUND  and D  __XREF__COMPOUND  are toxic metabolites of the marine dinoflagellate  Alexandrium ostenfeldii  that were isolated from the digestive glands of mussels ( Mytilus edulis ) and scallops ( Placopecten magellanicus ) during routine monitoring for diarrhetic shellfish toxins in Nova Scotia, Canada, in .1995 __REF__." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text you provided is classified under the "Method" category because it describes the empirical findings, outcomes, observations, or data generated by the research, specifically the determination of the Ginzburg temperature." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text provides information about the empirical findings, specifically the critical temperatures of the solutions, which is a key aspect of the research findings. Therefore, the category for this text is "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: For the C __SB__ isomer, ca." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: [decomposition of COMPOUND leads to aceanthrylene]" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: _______________________________" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.metrics:Ignoring 498 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 484 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 780 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 780 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: nan, -1.000, nan
guideline_match_Motivation_Result: nan, -1.000, nan
guideline_match_Method_Background: -0.714, 0.143, 0.714
guideline_match_Result_Method: -0.600, 0.600, 1.000

> guideline_match_Conclusion_Motivation:
guideline_match: -0.984, -0.969, -0.942

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.002, 1.007
tokens_per_sentence: 1.018, 1.062, 1.179
tokens_per_sample: 1.022, 1.104, 1.324
fkgl_readability: -2.827, -2.628, -2.377

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 22.000, 34.667, 46.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 7 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Background',
 'Method': 'Conclusion',
 'Motivation': 'Result',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that explains the reasons, objectives, or goals '
 'b ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that explains the reasons, objectives, or goals ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.metrics:Ignoring 539 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 697 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 226 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 751 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 751 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: nan, -1.000, nan
guideline_match_Motivation_Background: nan, 1.000, nan
guideline_match_Method_Result: nan, -1.000, nan
guideline_match_Result_Motivation: -0.429, 0.429, 1.000

> guideline_match_Conclusion_Method:
mean: -1.000
guideline_match: -0.992, -0.982, -0.964

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 14.576, 15.157, 15.701

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 8 of 50:
{'Background': 'Method',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Results."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.metrics:Ignoring 487 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 956 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 429 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 736 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 736 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.173, 0.259, 0.345
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Background: -0.955, -0.864, -0.636
guideline_match_Result_Result: -0.714, -0.143, 0.714

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: 0.096, 0.177, 0.257

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.002, 1.007
tokens_per_sentence: 1.000, 1.011, 1.038
tokens_per_sample: 1.000, 1.024, 1.084
fkgl_readability: 1.816, 2.434, 3.067

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: nan, 12.000, nan
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 9 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that provides context, foundational knowledge, or '
 'rel ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that provides context, foundational knowledge, or '
  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "The text provided can be classified into the following scientific concept category:
Method: The text provides information on the experimental design, data collection processes, and techniques used in the study. It includes details on the instrumentation and materials used, such as CDCl__SB__, M __SB__, and H __SP __Bu Ph __SB __." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Prediction "Background: The text provides information on the empirical findings, outcomes, observations, or data generated by the research, including quantitative and qualitative results, statistical analyses, and other information related to the research findings." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 545 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 939 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 470 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 779 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 778 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: 0.974, 0.996, 1.000
guideline_match_Motivation_Motivation: -1.000, -0.333, 0.667
guideline_match_Method_Result: nan, -1.000, nan
guideline_match_Result_Background: -0.143, 0.714, 1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: 0.687, 0.747, 0.800

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: 1.000, 1.039, 1.234
tokens_per_sample: 1.000, 1.039, 1.234
fkgl_readability: -1.858, -1.594, -1.296

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
mean: 39.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 10 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Background',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that presents the empirical findings, outcomes, '
 'o ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that presents the empirical findings, outcomes, ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text provided can be classified into the following scientific concept category:
Result: The text provides information on the empirical findings of the research, including the observed chemical shifts, coupling constants, and molecular structures of the compound. It also highlights the significance of the study, including the discovery of new signals and the implications for future research directions." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method: Smith and Martel summarized literature data for K __SB__ equal to 63 and 2.8 at ionic strengths of solutions equal to 3.0 and 0.0 (298 K), respectively." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Result" => "Result"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method:
The text mentions "an increase in internuclear separation for BiN" and "data collection processes used in the study," which suggests that the text is discussing the research methods used in the study. Therefore, the category is "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: (x) PBE0: One-parameter hybrid functional using Perdew, Burke and Ernzerhof's 1996 exchange and correlation __REF__  and three third-generation methods." => "Method"
WARNING:llms.metrics:Ignoring 464 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 13 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 722 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 722 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: nan, -1.000, nan
guideline_match_Motivation_Result: nan, 1.000, nan
guideline_match_Method_Method: 0.087, 0.181, 0.271

> guideline_match_Result_Motivation:
mean: 1.000

> guideline_match_Conclusion_Background:
mean: 1.000
guideline_match: -0.512, -0.457, -0.400

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.000, 1.006, 1.033
tokens_per_sample: 1.000, 1.012, 1.072
fkgl_readability: 8.368, 9.031, 9.707

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 12.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 11 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Result',
 'Method': 'Conclusion',
 'Motivation': 'Method',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that presents the empirical findings, outcomes, '
 'o ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that presents the empirical findings, outcomes, ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Concept: Motivation" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.metrics:Ignoring 635 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 928 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 560 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 681 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 681 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: -0.852, -0.797, -0.732

> guideline_match_Motivation_Background:
mean: 1.000
guideline_match_Method_Motivation: -0.694, -0.500, -0.278
guideline_match_Result_Conclusion: nan, 1.000, nan

> guideline_match_Conclusion_Method:
guideline_match: -0.795, -0.736, -0.664

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 2.449, 2.972, 3.517

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 12 of 50:
{'Background': 'Method',
 'Conclusion': 'Conclusion',
 'Method': 'Result',
 'Motivation': 'Background',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that describes the research methods, techniques, '
 ' ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that describes the research methods, techniques,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text can be classified under the category of "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.metrics:Ignoring 978 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 684 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 659 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 727 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 727 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.455, -0.091, 0.364

> guideline_match_Motivation_Result:
mean: -1.000
guideline_match_Method_Background: 0.766, 0.835, 0.886

> guideline_match_Result_Method:
mean: -1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: 0.689, 0.765, 0.830

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 6.851, 7.136, 7.410

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 13 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Observation" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Conclusion":
Conclusion" => "Conclusion"
WARNING:llms.classifiers.models:Fixing prediction: "Concept: Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method:" => "Method"
WARNING:llms.metrics:Ignoring 541 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 90 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 718 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 718 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: -0.712, -0.647, -0.573

> guideline_match_Motivation_Background:
mean: -1.000
guideline_match_Method_Method: 0.660, 0.727, 0.785
guideline_match_Result_Motivation: -1.000, 0.000, 1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: -0.033, 0.031, 0.095

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 2.541, 3.110, 3.703

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 14 of 50:
{'Background': 'Method',
 'Conclusion': 'Result',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that presents the empirical findings, outcomes, '
 'o ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that presents the empirical findings, outcomes, ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Result
XREF refers to an in-text citation or reference to a previous study or publication. In this case, the text is providing a result or finding from a study, specifically the distance and angles of a particular compound." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the research methodology used in the study, specifically the type of plating bath used to deposit silver. This information is relevant to the background of the study and helps readers understand the context in which the research was conducted. Therefore, the category for this text is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the similar behavior of silaffins from C. fusiformis, which is a scientific finding or result. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about a scientific concept or phenomenon (Result), specifically the relationship between the Ginzburg temperature and the crossover." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "REF: Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Conclusion":
Conclusion" => "Conclusion"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research topic, existing theories, and the broader scientific field in which the research is situated. It provides context and foundational knowledge about the research area, including the relationship between concentration and the shape transition of molecules. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about a specific scientific method (liquid chromatography) and its application in determining photosensitiser concentrations in blood, which is relevant to the field of pharmacology and toxicology. Therefore, it falls under the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, I would classify it under the category of "Reference":
Category: Reference" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the potential avoidance of a problem related to red blood cell aggregation after photodynamic therapy (PDT), which is a scientific concept. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.metrics:Ignoring 548 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 800 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 346 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 664 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 663 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: -0.540, -0.460, -0.376

> guideline_match_Motivation_Method:
guideline_match_Method_Background: -0.910, -0.850, -0.760
guideline_match_Result_Conclusion: nan, 1.000, nan

> guideline_match_Conclusion_Motivation:
guideline_match: -0.636, -0.575, -0.511

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.012
tokens_per_sentence: 1.010, 1.052, 1.151
tokens_per_sample: 1.022, 1.126, 1.392
fkgl_readability: 8.332, 8.917, 9.520

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.333, 2.000
tokens_diff: 22.000, 42.000, 54.333
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 15 of 50:
{'Background': 'Method',
 'Conclusion': 'Result',
 'Method': 'Conclusion',
 'Motivation': 'Motivation',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Background: This text provides background information on the research topic, existing theories, and prior studies, helping readers understand the context of the research." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: __REF__" => "Background"
WARNING:llms.metrics:Ignoring 541 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 967 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 497 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 712 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 712 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: -0.987, -0.969, -0.939
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Background: -0.939, -0.758, -0.455
guideline_match_Result_Conclusion: -1.000, -0.600, 0.600

> guideline_match_Conclusion_Method:
guideline_match: -0.956, -0.928, -0.889

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 2.537, 3.165, 3.794

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 16 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Result',
 'Method': 'Conclusion',
 'Motivation': 'Background',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that provides context, foundational knowledge, or '
  ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that provides context, foundational knowledge, or ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text provided falls under the category of "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.metrics:Ignoring 527 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 764 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 289 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 695 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 695 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: 0.886, 0.928, 0.958

> guideline_match_Motivation_Background:
guideline_match_Method_Result: -0.856, -0.788, -0.703
guideline_match_Result_Conclusion: -1.000, 0.000, 1.000

> guideline_match_Conclusion_Method:
guideline_match: 0.286, 0.356, 0.423

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 12.836, 13.440, 14.068

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 17 of 50:
{'Background': 'Result',
 'Conclusion': 'Method',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that presents the empirical findings, outcomes, '
 'o ... research is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that presents the empirical findings, outcomes, ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: __REF__" => "Background"
WARNING:llms.classifiers.models:Prediction "(x) Background: One-parameter hybrid functional using Perdew, Burke and Ernzerhof's 1996 exchange and correlation function and three third-generation methods." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 987 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 728 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 702 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 734 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 734 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: -0.077, 0.538, 0.846
guideline_match_Motivation_Motivation: -0.667, 0.000, 0.667
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Background: nan, 1.000, nan

> guideline_match_Conclusion_Result:
mean: -1.000
guideline_match: -0.919, -0.872, -0.805

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: 1.000, 1.024, 1.144
tokens_per_sample: 1.000, 1.024, 1.144
fkgl_readability: 5.949, 6.254, 6.543

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
mean: 24.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 18 of 50:
{'Background': 'Method',
 'Conclusion': 'Background',
 'Method': 'Result',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 "inte ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 " ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "Result
The text provides a summary of the findings related to the role of lipid rafts in diseases, highlighting the potential significance of these structures in various conditions, including virus infections, Alzheimer's disease, and prion diseases. The text does not provide detailed methodological information or background context, which suggests it belongs to the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text can be classified into the following scientific concept category:
Motivation: The text explains the reasons, objectives, or goals behind the research, including addressing a research gap, the problem being addressed, the significance of the study, and why the research is important." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the key findings and implications of the research in the field of asymmetric organic photochemistry, including the importance of chiral recognition in the excited state for achieving enantioselectivity during photosensitization and quenching processes. This category captures the main takeaways and insights derived from the study's results, including the broader significance of the findings, future research directions, and the study's contributions to the field." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text mentions the Ginzburg temperature, which is a key factor in determining the crossover, providing insight into the study's findings and implications for the field." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the key takeaways, implications, interpretations, or insights derived from the study's results, specifically the C __SB__ isomer." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Results."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the antitumor antibiotics, Bleomycins, and their mechanism of action, which is cleaving DNA in an oxidative manner, and their clinical use in treating squamous cell and malignant lymphomas. This information provides the key takeaways, implications, and interpretations of the study's results, highlighting the broader significance of the findings and suggesting future research directions. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the potential applications of CdS nanoparticles, which is the main result of the research. It highlights the exciting applications of these nanoparticles and the attention they have received in the scientific community." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the study's findings, specifically the relationship between concentration and the change in molecular structure induced by ionic strength, which leads to cylinder-to-disk transitions. This category is the most appropriate classification for the text." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the key takeaways and insights derived from the study's results, specifically mentioning the belief that DNA-binding is responsible for the antitumor activity and the necessary condition of intercalation. This falls under the "Result" category." => "Result"
WARNING:llms.metrics:Ignoring 476 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 957 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 426 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: nan, -1.000, nan
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Background: nan, -1.000, nan

> guideline_match_Result_Method:

> guideline_match_Conclusion_Result:
mean: 1.000
guideline_match: -0.990, -0.976, -0.951

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.005
tokens_per_sentence: 1.000, 1.032, 1.168
tokens_per_sample: 1.000, 1.064, 1.340
fkgl_readability: 0.624, 1.070, 1.544

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 64.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 19 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Method',
 'Method': 'Conclusion',
 'Motivation': 'Background',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that summarizes the key takeaways, implications, '
 "inte ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that summarizes the key takeaways, implications, '
 " ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, I would classify it under the category of "Scientific Concept."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: "It was suggested in REF that an increase in internuclear separation for BiN may be considered a step toward the potential curve asymptote at which both atoms have the spherically symmetric electron distribution of their ground states, SP S SB."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.metrics:Ignoring 635 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 943 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 568 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.863, -0.808, -0.742
guideline_match_Motivation_Background: -1.000, 0.333, 1.000
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Result: -0.714, -0.143, 0.714

> guideline_match_Conclusion_Method:
guideline_match: -0.866, -0.815, -0.755

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.000, 1.010, 1.057
tokens_per_sample: 1.000, 1.020, 1.120
fkgl_readability: -0.017, 0.378, 0.809

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 20.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 20 of 50:
{'Background': 'Background',
 'Conclusion': 'Result',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that explains the reasons, objectives, or goals behind '
 ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that explains the reasons, objectives, or goals behin ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method: "It was suggested in REF that an increase in internuclear separation for BiN may be considered a step toward the potential curve asymptote at which both atoms have the spherically symmetric electron distribution of their ground states, SP S SB."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 448 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 793 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 793 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: nan, -1.000, nan
guideline_match_Motivation_Method: nan, 1.000, nan
guideline_match_Method_Result: -1.000, -0.333, 0.667
guideline_match_Result_Conclusion: nan, -1.000, nan

> guideline_match_Conclusion_Motivation:
guideline_match: -0.993, -0.982, -0.960

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: -3.038, -2.836, -2.575

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 21 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Motivation',
 'Motivation': 'Method',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that presents the empirical findings, outcomes, '
 'o ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that presents the empirical findings, outcomes, ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: __REF__" => "Background"
WARNING:llms.metrics:Ignoring 969 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 779 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 739 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 718 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 718 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: nan, -1.000, nan
guideline_match_Motivation_Method: nan, -1.000, nan
guideline_match_Method_Motivation: -0.946, -0.900, -0.828
guideline_match_Result_Background: nan, 1.000, nan

> guideline_match_Conclusion_Conclusion:
mean: -1.000
guideline_match: -0.923, -0.870, -0.801

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 5.576, 5.933, 6.279

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 22 of 50:
{'Background': 'Method',
 'Conclusion': 'Conclusion',
 'Method': 'Motivation',
 'Motivation': 'Background',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Concept: Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Results."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.metrics:Ignoring 733 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 795 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 519 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 621 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 621 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.685, -0.596, -0.491

> guideline_match_Motivation_Method:
mean: -1.000
guideline_match_Method_Background: -0.405, -0.278, -0.141
guideline_match_Result_Result: -0.143, 0.714, 1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: -0.518, -0.439, -0.356

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.000, 1.006, 1.033
tokens_per_sample: 1.000, 1.012, 1.072
fkgl_readability: 5.355, 5.783, 6.220

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 12.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 23 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Background',
 'Motivation': 'Method',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that explains the reasons, objectives, or goals behind '
 ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that explains the reasons, objectives, or goals behin ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information on the outcome of the research, specifically the preparation of novel photocatalysts for photocatalytic water splitting. It mentions the materials used, their structure, and the conditions under which the reactions occurred. The text also mentions the expected outcomes of the research, such as the production of H2 and O2. Therefore, the category "Result" is the most appropriate for this text." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text explains the reasons, objectives, or goals behind the research, specifically the importance of combining haemolysis with met-haemoglobin formation in the Photo-RBC test. It highlights the research gap and the problem being addressed, and provides context for the study by discussing the known occurrences of photodynamic reactions and their consequences." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a brief explanation of the research goal or objective, which is a characteristic of the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text explains the reasons or goals behind the research, specifically stating that the treatment with antimicrobial agents results in a non-effective therapy." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "(Motivation)" => "Motivation"
WARNING:llms.classifiers.models:Prediction "Result
The text provides information on the reasons, objectives, or goals behind the research, specifically the explanation of the research gap and the problem being addressed. It does not provide details on the research methods, techniques, or procedures used, nor does it provide background information on the topic or existing theories. Therefore, the category that best fits this text is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result
The text provides a brief explanation of the research conducted by Walters et al. and the findings of their study, including the mechanism of thermal decomposition of alkali metal aluminohydrides. It does not provide detailed descriptions of the research methods, techniques, or data collection processes used in the study, or provide background information on the topic or existing theories. Therefore, the most appropriate category for the text is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text explains the reasons, objectives, or goals behind the research, specifically the belief that DNA-binding is the mechanism underlying the antitumor activity of certain compounds. It mentions the necessary condition of intercalation, which is a key finding of the study. Therefore, the text belongs to the "Result" category." => "Result"
WARNING:llms.metrics:Ignoring 465 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 935 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 396 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 728 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 726 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: -0.181, -0.099, -0.017
guideline_match_Motivation_Result: nan, 1.000, nan
guideline_match_Method_Motivation: -0.354, -0.108, 0.138

> guideline_match_Result_Background:

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: -0.169, -0.093, -0.013

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.005, 1.019
tokens_per_sentence: 1.000, 1.043, 1.151
tokens_per_sample: 1.000, 1.152, 1.544
fkgl_readability: 3.143, 3.756, 4.396

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 2.000, 2.500, 3.000
tokens_diff: 72.000, 76.000, 80.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 24 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Background',
 'Method': 'Result',
 'Motivation': 'Conclusion',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'o ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: For the C __SB__ isomer, ca." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.metrics:Ignoring 462 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 451 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 794 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 794 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: -1.000, -0.996, -0.979
guideline_match_Motivation_Background: nan, -1.000, nan
guideline_match_Method_Result: -1.000, 0.333, 1.000
guideline_match_Result_Method: -0.600, 0.600, 1.000

> guideline_match_Conclusion_Motivation:
guideline_match: -0.989, -0.974, -0.949

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: -3.227, -3.073, -2.859

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 25 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Method',
 'Method': 'Result',
 'Motivation': 'Background',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'o ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Method: COMPOUND" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: The ground state of an alkali atom is not stable on surfaces of carbon or metal oxide, which means that such atoms easily desorb thermally as Rydberg species." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: D00(NH) = (31 000 ± 500) cm." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: These include integration of electrophoretic product sizing on a monolithic device, as well as optimization of conditions to provide faster PCR (under 7 minutes), single-molecule detection, real-time applications, and multiplexing." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: The text provides information about the empirical findings, outcomes, observations, or data generated by the research, specifically regarding the stability of the Pitzer salt compound." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Prediction "Method: The text describes the determination of the crossover temperature by the Ginzburg temperature, which is a quantitative and qualitative result of the research." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text provides information about the empirical findings, specifically the critical temperatures of the solutions, which are near room temperature. Therefore, it belongs to the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: For the C __SB__ isomer, ca." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: For pyrrole there are some disagreements, most notably for the states involving ν __SB__." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: _______________________________" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.metrics:Ignoring 482 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 466 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 783 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 783 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: -0.992, -0.981, -0.958
guideline_match_Motivation_Result: nan, -1.000, nan
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Method: nan, 1.000, nan

> guideline_match_Conclusion_Background:
mean: -1.000
guideline_match: -0.978, -0.959, -0.929

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: 1.000, 1.026, 1.156
tokens_per_sample: 1.000, 1.026, 1.156
fkgl_readability: -3.072, -2.911, -2.697

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
mean: 26.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 26 of 50:
{'Background': 'Result',
 'Conclusion': 'Background',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: __REF__" => "Background"
WARNING:llms.metrics:Ignoring 801 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 342 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 689 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 689 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: nan, -1.000, nan
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Method: -0.244, -0.154, -0.065
guideline_match_Result_Background: -0.667, 0.333, 1.000

> guideline_match_Conclusion_Result:
guideline_match: -0.462, -0.395, -0.322

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 7.632, 8.130, 8.616

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 27 of 50:
{'Background': 'Background',
 'Conclusion': 'Method',
 'Method': 'Motivation',
 'Motivation': 'Conclusion',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: "It was suggested in  __REF__  that an increase in internuclear separation for BiN may be considered a step toward the potential curve asymptote at which both atoms have the spherically symmetric electron distribution of their ground states, __SP__ S __SB__. __REF__"" => "Method"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 995 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 446 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 778 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 778 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -1.000, -0.996, -0.978
guideline_match_Motivation_Method: nan, 1.000, nan
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Result: -1.000, -0.429, 0.429

> guideline_match_Conclusion_Motivation:
mean: -1.000
guideline_match: -0.993, -0.982, -0.960

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: -1.805, -1.426, -0.987

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 28 of 50:
{'Background': 'Motivation',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Background',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
__Motivation__" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Results" => "Result"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.metrics:Ignoring 467 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 12 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 693 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 693 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Motivation: 0.809, 0.857, 0.899

> guideline_match_Motivation_Background:
guideline_match_Method_Method: -0.324, -0.235, -0.141
guideline_match_Result_Result: -0.429, 0.429, 1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: 0.302, 0.360, 0.419

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.006, 1.016, 1.044
tokens_per_sample: 1.012, 1.036, 1.096
fkgl_readability: 14.450, 15.042, 15.603

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: nan, 12.000, nan
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 29 of 50:
{'Background': 'Background',
 'Conclusion': 'Result',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Method: (31 000 ± 500) cm." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method:
The text describes the research methods used in the study, including the measurements based on resonant photoionization of the neutral π-bound In–Ar dimer via the S__SB__ state." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method:
The text describes the research methods used in the study, specifically the reference mentioned in the text and the experimental design used to investigate the potential curve asymptote of BiN." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: ( x ) PBE0: One-parameter hybrid functional using Perdew, Burke and Ernzerhof's 1996 exchange and correlation __REF__  and three third-generation methods:" => "Method"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 4 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 757 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 757 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -0.996, -0.985, -0.963
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Method: 0.951, 0.978, 0.991
guideline_match_Result_Conclusion: -1.000, -0.500, 0.500

> guideline_match_Conclusion_Result:
guideline_match: -0.153, -0.090, -0.028

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: -1.189, -0.750, -0.264

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 30 of 50:
{'Background': 'Method',
 'Conclusion': 'Background',
 'Method': 'Motivation',
 'Motivation': 'Result',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 "inte ... arch '
 'is important.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that summarizes the key takeaways, implications, '
 " ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Result

The category "Result" is most relevant for the given text, as it summarizes the key takeaways from the study's findings. The text highlights the challenges of avoiding the disappearance of conformer peaks during sample cooling and explains why this phenomenon is difficult to avoid, particularly when low-energy pathways of interconversion are available." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the key takeaways from the study, specifically the ability to determine the size of droplets with nanometre precision when coupled with CERS. This information highlights the broader significance of the findings, suggests future research directions, and reiterates the study's contributions to the field. Therefore, it belongs to the category of Result." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the findings and implications of the study, suggesting that lipid rafts may play a central role in various diseases such as viral infections, Alzheimer's disease, and prion diseases." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text describes the findings of the research, specifically the potential barriers separating minima of competitive energy in the molecule Glycine, and provides insights into the significance of these findings. Therefore, it belongs to the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the study's findings, specifically that the ground state of an alkali atom is not stable on surfaces of carbon or metal oxide, which means that such atoms easily desorb thermally as Rydberg species. This information indicates the broader significance of the study's results and suggests future research directions. Therefore, the category is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text classifies under the result category because it summarizes the key takeaway of the study, which is the separation of sialylglycopeptide (SGP) from hen's egg yolk." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the intrinsic viscosity value of a system constituted of perfect spheres, which is 2.5, and how this value depends on the shape of molecules. This information is a result of the study and provides key takeaways, implications, and insights into the field of research." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the study's findings, specifically the basic strength of potassium exchanged Y zeolite (KY) for the reaction of bromobenzene and phenylboronic acid. This information is classified under the "Result" category as it presents the key takeaways, implications, and insights derived from the study's results." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The category "Result" is the most appropriate classification for the given text." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the research findings, including the integration of electrophoretic product sizing on a monolithic device, optimization of conditions to provide faster PCR (under 7 minutes), single-molecule detection, real-time applications, and multiplexing. Therefore, the category that best fits this text is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text can be classified into the following category:
* Motivation: The text provides information about the research gap, the problem being addressed, and the significance of the study. It explains why the research is important and highlights the empirical findings, outcomes, observations, or data generated by the research.
The category name is "Motivation."" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the study's findings, specifically highlighting the distortion of the minimized geometry in favor of strengthening hydrogen-bonding interactions. This falls under the category of "Result" as it outlines the key takeaways and implications of the study's findings." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the key takeaways, implications, interpretations, or insights derived from the study's results, specifically discussing the stability of the Pitzer salt compound and its significance in the scientific field. Therefore, the category "Result" best categorizes the text." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides a summary of the results of the study, highlighting the key findings and implications of the research. It does not provide context or background information, nor does it describe the research methods or goals of the study. Therefore, the most appropriate category for the text is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result

The text provides a concise description of the research method used in the study, specifically the type of plating bath used and the plating technique employed. Therefore, it belongs to the category of "Method."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The category "Result" is the most appropriate classification for the given text." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
XREF stands for "cross-referencing," which is a common convention used in scientific writing to indicate a reference or citation to another source or location in the text. In this case, the text is classified as a "result" because it summarizes the toxic metabolites of a marine dinoflagellate that were isolated from digestive glands of mussels and scallops in Nova Scotia in 1995." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a comparison of the behavior of silaffins from C. fusiformis, indicating similarities between the two. This information suggests insights into the nature of these organisms and may have implications for future research directions in the field. Therefore, the category "Result" is most appropriate." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text you provided suggests that the Ginzburg temperature is a determining factor in the crossover, which is a key takeaway from the study. Therefore, the most appropriate category for this text is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the research findings, specifically mentioning the production of silicon and germanium nanowires within mesoporous silica powders using a supercritical fluid inclusion technique. Therefore, the category "Result" is the most appropriate classification for the text." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the critical temperatures of the solutions, which are near room temperature. This information is a key takeaway from the study and has implications for future research directions." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the key takeaways, implications, interpretations, or insights derived from the study's results, and does not provide context, foundational knowledge, or relevant information about the research topic or existing theories. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the revisions made to Ramsey's theory of shielding to account for relativistic effects, highlighting the broader significance of the findings and suggesting future research directions. Therefore, it belongs to the category of Result." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides a summary of the key findings or implications of the research, rather than the research methods or background information. The category "Result" is the most appropriate classification for this text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the antitumor antibiotics, Bleomycins (BLMs), and their mechanism of action, which is to cleave DNA in an oxidative manner. It also mentions their clinical use for the treatment of specific types of cancer, including squamous cell and malignant lymphomas. This information fits into the "Result" category as it presents the key takeaways and implications of the study on the use of Bleomycins in cancer treatment." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the key findings and implications of the research on heterogeneous catalysts, including the dependence of activity on the interaction between metals and oxides. This information is most relevant to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text describes the outcome or implications of the research, rather than providing context, background information, or motivation for the study. Therefore, it best fits into the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of a recent research study, highlighting the key findings and implications of the study. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a summary of the potential applications of CdS nanoparticles and the focused attention on their synthesis, size control, and organization due to these applications. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the study's findings, specifically stating that the treatment with antimicrobial agents is ineffective. This information falls under the category of "Result" as it summarizes the key takeaways from the study's findings." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text describes the key findings of the study, specifically the relationship between concentration and the shape transition of molecules. It highlights the broader significance of the study's findings, including the implications for the field of chemistry and the potential for future research directions. Therefore, the category that best fits this text is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the study's findings, which is the purpose of the Result category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text describes a specific observation or finding related to the study's results, and provides insight into the implications or significance of the research. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides a summary of the key findings and implications of the research on the genotoxicity of radiation, highlighting the connection between the presence of certain radicals and mutations in DNA. It does not provide background information or methodological details, but rather summarizes the main results and implications of the study. Therefore, the category "Result" is the most appropriate classification for the given text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
Scientific concept: __REF__" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides a summary of the study's findings, specifically the classification of xylanases based on amino acid sequence similarities. It highlights the broader significance of the research, including the identification of families 10 and 11 of glycosyl hydrolases, and suggests future research directions. Therefore, it belongs to the category of Result." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides a summary of the key findings or implications of the research, rather than providing context, foundational knowledge, or background information. Therefore, it belongs to the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text summarizes the key findings and implications of the study, specifically the relationship between DNA-binding and antitumor activity, and how intercalation plays a necessary role in this process. Therefore, the category that best fits this text is "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text summarizes the key findings of the study, highlighting the problem of enhanced red blood cell aggregation after PDT and the potential solution of using a mixture of antioxidants to avoid this problem. It does not provide context or background information, but rather focuses on the research question and the results obtained. Therefore, the appropriate category is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 471 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 682 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 149 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 991 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 725 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 720 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: nan, -1.000, nan
guideline_match_Motivation_Method: nan, -1.000, nan
guideline_match_Method_Background: -1.000, -0.987, -0.956

> guideline_match_Result_Motivation:
mean: -1.000

> guideline_match_Conclusion_Result:
guideline_match: -1.000, -0.995, -0.984

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.005, 1.012, 1.023
tokens_per_sentence: 1.067, 1.151, 1.292
tokens_per_sample: 1.166, 1.378, 1.748
fkgl_readability: 7.132, 7.463, 7.789

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.111, 1.333, 1.667
tokens_diff: 29.222, 42.000, 54.778
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 31 of 50:
{'Background': 'Background',
 'Conclusion': 'Motivation',
 'Method': 'Method',
 'Motivation': 'Conclusion',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that presents the empirical findings, outcomes, '
 'obser ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that presents the empirical findings, outcomes, '
 'o ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the disappearance of conformer peaks during sample cooling and the challenges associated with avoiding this phenomenon. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
XREF refers to a reference or citation in the text, indicating that the information being presented is based on previous research or studies." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings or results of the research, specifically the ability to determine the size of droplets with nanometre precision using CERS. This falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides empirical findings, observations, and data related to the research topic, indicating the potential central role of lipid rafts in various diseases. Therefore, it falls under the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the potential energy of a molecule, specifically glycine, and the related energy minima. This information is typically presented in a scientific paper as a result of the research, providing empirical findings related to the study of molecular properties." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings or results of the research, specifically the separation of Sialylglycopeptide (SGP) from hen's egg yolk. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides empirical findings, specifically the intrinsic viscosity value of a system composed of perfect spheres, which is equal to 2.5 and depends on the shape of molecules. Therefore, it belongs to the Result category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings of the study, specifically the basic strength of the potassium exchanged Y zeolite (KY) for the reaction of bromobenzene and phenylboronic acid. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information on the research findings, specifically the variation in the lattice constant of FeO(111) monolayer films as a result of the interaction at the specific interface. This information is classified under the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "The text can be classified into the following scientific concept category:
Motivation: The text provides insights into the significance of the research findings, suggesting future research directions and reiterating the study's contributions to the field." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings, specifically the literature data summarized by Smith and Martel, and the results of their research on K __SB __ equal to 63 and 2.8 at different ionic strengths of solutions at 298 K. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings or data generated by the research, specifically regarding the caution required when viewing MP2 and CCSD energies. Therefore, it falls under the "Result" category." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the limitations of a specific experimental method (conventional gas-phase IR spectroscopy) when attempting to analyze glycine, which is a low-thermal-stability molecule. Therefore, it belongs to the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the assignment of an extended X-ray absorption fine structure (EXAFS) signature to chloride bound to Mn-oxo model clusters. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information about the empirical findings or data generated by the research, specifically the stability of a particular compound. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the method used to deposit silver, which is a specific empirical finding or outcome of the research. Therefore, it belongs to the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically highlighting the importance of chiral recognition in the excited state for achieving enantioselectivity during photosensitization and quenching processes in asymmetric organic photochemistry. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides empirical findings, observations, and data related to the research topic. It mentions the origin of a behavior, which is a result of the study, and includes quantitative and qualitative information. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings, observations, or data generated by the research, which falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the applicability of the exciton model to clusters with spatial dimensions between 1 and 10 nm, and the vibrational band shape of NSBO clusters. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text you provided is a sentence that presents the empirical findings or research results, therefore it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the reliability of a calculation based on cluster size and computational resources, which is a finding or observation from the research. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the findings of the study, specifically the consistency of certain behaviors with previous observations. Therefore, it belongs to the category of "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings or results of the research, specifically the determination of the crossover temperature by the Ginzburg temperature. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the production of silicon and germanium nanowires within mesoporous silica powders using a supercritical fluid inclusion technique. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text "PCC 6803 as described previously" does not provide any information about the motivation, background, or methodology of the research, but rather refers to a specific empirical finding or result. Therefore, the most appropriate category for this text is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings or data generated by the research, specifically the critical temperatures of solutions near room temperature. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings or results of the research, specifically the value of the C __SB__ isomer. Therefore, it belongs to the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically mentioning the revision of Ramsey's theory of shielding to account for relativistic effects. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides empirical findings, specifically the calculation of infrared spectra of molecular ions using ab initio techniques, which are relevant to ion-molecule reaction schemes and the production of interstellar molecules. This information falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings, specifically the transition of the HOMO and LUMO of the molecule under study. This falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the structures on the length scales of 1 nm to 10 μm in the biological membrane, which affect lateral diffusion, hence it falls under the result category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides an expectation or prediction about the results of a research study, specifically regarding the formation of BFPT complexes in anionic complexes of glycine with thymine. It does not provide any empirical findings, outcomes, observations, or data, but rather presents a theoretical or conceptual framework for understanding the phenomenon. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the nature of heterogeneous catalysts and how their activity depends on the interaction between different components. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the fact that the C-SB- conformation is different and does not allow for the formation of a C-SB- ring. This information is categorized as a result, as it presents empirical findings or data generated by the research." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the evolutionary steps and the constructed optimal solution, which are the empirical results of the study. Therefore, it belongs to the Result category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the formation of monolayers using chemical bonds between metals and heavy chalcogens. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides empirical findings, specifically the outcome of treatment with antimicrobial agents, which are not effective. Therefore, it fits into the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides empirical findings, specifically the identification of molecular markers that can accurately define aggressive and poorly prognostic neoplasms. This information falls under the result category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text mentions "SANS data for another protein, lysozyme" and "a more compact fold," which suggests that the text is presenting empirical findings or data generated by the research. Therefore, the most appropriate category for this text is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text mentions the rational design of pharmaceuticals, chiral sensors, and molecular devices, which are the empirical findings, outcomes, and data generated by the research. Therefore, the category for this text is "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides empirical findings, specifically the experimental proof of a mechanism of defect creation provided by a recent study using synchrotron radiation. Therefore, it belongs to the Result category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The category "Result" best fits the text provided." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the findings of a study on the genotoxicity of radiation, including the presence of certain radicals and their connection to DNA mutations. This information falls under the category of "Result" because it presents the empirical findings of the research." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the method used to determine photosensitiser concentrations in blood, which is a result of the research. Therefore, it belongs to the category of "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result: It was suggested in __REF__ that an increase in internuclear separation for BiN may be considered a step toward the potential curve asymptote at which both atoms have the spherically symmetric electron distribution of their ground states, __SP__ S __SB__." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the empirical results of the study. It mentions the possibility of assuming that most of the small molecules are waters or hydroxides, which is a quantitative result of the study. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the classification of xylanases based on their amino acid sequence similarities, which is a result of the research. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research findings, specifically the analysis performed at the natural bond orbital (NBO) level, which is a quantitative result of the study. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the empirical findings, observations, or data generated by the research, which falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information on the research findings, specifically the avoidance of red blood cell aggregation after PDT through the use of a mixture of antioxidants. This falls under the category of "Result."" => "Result"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 5 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 717 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 715 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -0.993, -0.981, -0.959
guideline_match_Motivation_Conclusion: nan, -1.000, nan
guideline_match_Method_Method: -0.454, -0.369, -0.284
guideline_match_Result_Result: nan, 1.000, nan

> guideline_match_Conclusion_Motivation:
guideline_match: -0.735, -0.692, -0.646

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.010
tokens_per_sentence: 1.020, 1.079, 1.196
tokens_per_sample: 1.041, 1.162, 1.401
fkgl_readability: 6.379, 6.679, 6.960

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 35.000, 40.500, 48.500
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 32 of 50:
{'Background': 'Background',
 'Conclusion': 'Motivation',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that describes the research methods, techniques, '
 'proc ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that describes the research methods, techniques, '
 ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text can be classified under the category of "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text describes the accuracy and reliability of the research methods used in the study, specifically the error range of the reported values, which falls within the scope of the "Method" category." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: The text describes the research methods used to study the stability of the Pitzer salt compound." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: Spirolides B and D are toxic metabolites of the marine dinoflagellate Alexandrium ostenfeldii that were isolated from the digestive glands of mussels and scallops during routine monitoring for diarrhetic shellfish toxins in Nova Scotia, Canada, in 1995." => "Method"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method: For the C __SB__ isomer, ca." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: _______________________________" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: A sentence that describes the research methods, techniques, procedures, and data collection processes used in the study." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: (x) PBE0: One-parameter hybrid functional using Perdew, Burke and Ernzerhof's 1996 exchange and correlation __REF__  and three third-generation methods." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: ___REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 6 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 759 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 759 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -0.796, -0.740, -0.681

> guideline_match_Motivation_Conclusion:
mean: -1.000
guideline_match_Method_Method: 0.866, 0.911, 0.942
guideline_match_Result_Motivation: -0.429, 0.429, 1.000

> guideline_match_Conclusion_Result:
guideline_match: -0.050, 0.010, 0.074

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.000, 1.006, 1.033
tokens_per_sample: 1.000, 1.012, 1.072
fkgl_readability: -1.968, -1.662, -1.296

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 12.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 33 of 50:
{'Background': 'Result',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Background'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that provides context, foundational knowledge, or '
 'rel ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that provides context, foundational knowledge, or '
  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides contextual information about the research topic, specifically detailing the phenomenon of disappearing conformer peaks during sample cooling and the challenges associated with it." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information about a scientific concept, specifically the ability to determine the size of droplets with nanometre precision when using CERS. It provides foundational knowledge or relevant information about the research topic and the broader scientific field." => "Result"
WARNING:llms.classifiers.models:Prediction "Result
The text provides contextual information about the role of lipid rafts in various diseases, suggesting that they may play a central role in these conditions. This falls under the category of "Result" as it provides background information that helps readers understand the research topic and its relevance to the broader scientific field." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the potential energy landscape of glycine, which is a scientific concept related to the field of chemistry and physics. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides contextual information about the intrinsic viscosity value of a system constituted of perfect spheres, which is an existing scientific concept. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the measurement of a reaction and the dominant channel at room temperature, which is a result of the research. Therefore, it fits best into the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Prediction "Result
The text provides information about the ionization breakdown pattern of larger molecular clusters and the factors that influence it, which helps readers understand the background against which the research is conducted. Therefore, it fits into the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The text provided can be classified into the following scientific concept category:
Result: The text provides information on the empirical findings, outcomes, observations, or data generated by the research. It includes quantitative and qualitative results, statistical analyses, tables, figures, and any other information related to the research findings. Specifically, the text details the chemical shifts, coupling constants, and molecular weights of the compound studied." => "Result"
WARNING:llms.classifiers.models:Prediction "Background: This text provides an example of empirical findings, outcomes, observations, or data generated by the research, including quantitative and qualitative results, statistical analyses, and other information related to the research findings." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides contextual information about the low thermal stability of glycine, which is relevant to the research topic of analyzing the molecule using conventional gas-phase IR spectroscopy. Therefore, it falls under the category of Result." => "Result"
WARNING:llms.classifiers.models:Prediction "Result
The text provides contextual information about the research topic, specifically detailing the type of bond fission that occurs in a particular situation. It helps readers understand the background against which the research is conducted and provides foundational knowledge about the subject matter. Therefore, the category "Result" best fits the text." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the method used to deposit silver, which is a result of the research. It provides context and foundational knowledge about the research process, helping readers understand the background against which the research is conducted. Therefore, this text belongs to the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides context and foundational knowledge about the research topic, existing theories, and the broader scientific field in which the research is situated. It explains the importance of chiral recognition in the excited state for achieving enantioselectivity during photosensitization and quenching processes in asymmetric organic photochemistry." => "Result"
WARNING:llms.classifiers.models:Prediction "Result
The text provides contextual information about the tricritical point, which is a specific point on the coexistence curve where a line of second-order transitions intersects. This information helps readers understand the background against which the research is conducted, particularly in the field of phase transitions and critical phenomena." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result
The text provides contextual information about the research topic, specifically comparing the behavior of silaffins from C. fusiformis. This information helps readers understand the background against which the research is conducted and provides foundational knowledge about the species being studied. Therefore, the text belongs to the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides contextual information about the Ginzburg temperature and its relationship to the crossover, which is a fundamental concept in the field of condensed matter physics. Therefore, it belongs to the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Result
The text provides contextual information about the research topic, existing techniques, and the research gap addressed in the study. It explains the methodology used to produce silicon and germanium nanowires within mesoporous silica powders, but does not provide the empirical findings or results of the study. Therefore, it falls under the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information about the critical temperatures of solutions, which is a scientific concept related to the field of chemistry. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides contextual information about the C __SB__ isomer, which is a scientific concept in the field of chemistry. Therefore, it falls under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Result
The text provides contextual information about the research topic, existing theories, and the broader scientific field in which the research is situated. It helps readers understand the background against which the research is conducted, specifically by mentioning that several authors have revised Ramsey's theory of shielding to account for relativistic effects." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the decomposition of a compound and the resulting compound, which is a scientific fact or observation. It does not provide context, explain the reasons behind the research, describe the research methods, present the empirical findings, or summarize the key takeaways from the study. Therefore, the most appropriate category for this text is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result

The text provides background information on the composition and activity of heterogeneous catalysts, which is the scientific concept being studied. It provides context and foundational knowledge about the field, without presenting any specific research question or methodology. Therefore, it falls under the "Result" category." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about a recent development or discovery in a scientific field, specifically the formation of monolayers using chemical bonds between metals and heavy chalcogens. This information is intended to provide context and background knowledge for readers unfamiliar with this topic, and helps them understand the research area in which the study is situated. Therefore, the category is "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result
The text provides information about the potential applications of CdS nanoparticles, which is relevant background knowledge for understanding the research topic." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Result
The text provides contextual information about the importance of identifying molecular markers that can accurately define aggressive neoplasms and their poor prognosis, which is essential for understanding the background of the research field." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text provides information about the research topic, existing theories, and the broader scientific field in which the research is situated. It provides context and foundational knowledge about the relationship between concentration and ionic strength and their effects on molecular structure." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information about a scientific phenomenon (red-shift in reflection mode) and its relationship to the interparticle distance, which is a foundational concept in the field of physics. Therefore, it belongs to the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the method used to determine photosensitiser concentrations in blood, which is a result of the research. It does not explain the reasons or goals behind the research, describe the research methods used, present empirical findings, or summarize the key takeaways from the study. Therefore, it falls under the category of "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Background: The text provides information on the empirical findings, outcomes, observations, or data generated by the research, including quantitative and qualitative results, statistical analyses, and other relevant data." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information about the classification of xylanases based on amino acid sequence similarities, which is a result of the research on the topic." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides contextual information about the research topic, existing theories, and the broader scientific field in which the research is situated. It explains the beliefs about the mechanisms underlying the research topic and provides information about the necessary conditions for antitumor activity." => "Result"
WARNING:llms.classifiers.models:Prediction "Result
The text provides information about the research findings, specifically the avoidance of enhanced red blood cell aggregation after PDT by using a mixture of antioxidants. This information falls under the category of "Background."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.metrics:Ignoring 623 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 169 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 987 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 983 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 704 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 693 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Result: 0.873, 0.920, 0.952
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Method: -0.485, -0.405, -0.320

> guideline_match_Result_Background:

> guideline_match_Conclusion_Conclusion:
mean: -1.000
guideline_match: 0.138, 0.206, 0.271

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.012, 1.021, 1.036
tokens_per_sentence: 1.247, 1.410, 1.663
tokens_per_sample: 1.524, 1.865, 2.382
fkgl_readability: 6.806, 7.093, 7.364

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.308, 1.615, 1.846
tokens_diff: 44.353, 50.882, 56.471
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 34 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Method',
 'Method': 'Background',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.metrics:Ignoring 555 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 944 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 486 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 712 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 712 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Method: -0.429, -0.344, -0.254
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Result: -0.714, -0.143, 0.714

> guideline_match_Conclusion_Background:
guideline_match: -0.475, -0.397, -0.315

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 5.275, 5.962, 6.625

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 35 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Result',
 'Motivation': 'Method',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Scientific concept: Motivation" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Concept: Reaction paths" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Scientific concept: Motivation" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Method" => "Method"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text you provided, the category that best fits is:
Scientific concept: __REF__" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Results" => "Result"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 687 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 144 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 648 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 648 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -0.826, -0.777, -0.722
guideline_match_Motivation_Result: nan, -1.000, nan
guideline_match_Method_Motivation: -0.808, -0.738, -0.655

> guideline_match_Result_Method:
mean: -1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: -0.801, -0.762, -0.717

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.006, 1.023, 1.061
tokens_per_sample: 1.012, 1.046, 1.127
fkgl_readability: 9.390, 9.857, 10.331

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 5.250, 11.500, 17.250
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 36 of 50:
{'Background': 'Background',
 'Conclusion': 'Method',
 'Method': 'Result',
 'Motivation': 'Motivation',
 'Result': 'Conclusion'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'obser ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Method: A sentence that presents the empirical findings, outcomes, '
 'o ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Method: D00(NH) = (31 000 ± 500) cm." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text provided can be classified into the following scientific concept category:
Method: The text provides information on the experimental design, data collection processes, and statistical analyses used in the study. It includes details on the experimental conditions, such as the solvent used (CDCl3), the temperature (400 MHz, CDCl3), and the spectroscopic methods employed (1H NMR, 13C NMR, and EI-MS)." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: Smith and Martel summarized literature data for K __SB__ equal to 63 and 2.8 at ionic strengths of solutions equal to 3.0 and 0.0 (298 K), respectively." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Prediction "Method: The text describes the findings and data generated by the research on the stability of Pitzer salt. It includes statements about the empirical results, statistical analyses, and any other information related to the research findings." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Method: Spirolides B  __XREF__COMPOUND  and D  __XREF__COMPOUND" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method

The text provides information about the experimental conditions and data collection processes used in the study, which falls under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: For the C __SB__ isomer, ca." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __XREF__COMPOUND" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: __REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: (x) PBE0: One-parameter hybrid functional using Perdew, Burke and Ernzerhof's 1996 exchange and correlation __REF__  and three third-generation methods:" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method: ___REF__" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Method." => "Method"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 446 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 793 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 793 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -1.000, -0.996, -0.978
guideline_match_Motivation_Motivation: -0.333, 0.667, 1.000
guideline_match_Method_Conclusion: nan, -1.000, nan
guideline_match_Result_Method: nan, 1.000, nan

> guideline_match_Conclusion_Result:
mean: -1.000
guideline_match: -0.978, -0.957, -0.924

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.000, 1.020, 1.117
tokens_per_sample: 1.000, 1.040, 1.240
fkgl_readability: -3.294, -3.152, -2.943

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 40.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 37 of 50:
{'Background': 'Conclusion',
 'Conclusion': 'Background',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals '
 'b ... arch is '
 'conducted.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Motivation: A sentence that explains the reasons, objectives, or goals ' ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Method
The text provides information about the research methods used in the study, specifically the SSE method and the isotopes being studied. Therefore, it belongs to the category "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Background"." => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Method: S" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Motivation:
The text explains the reasons and objectives behind the research, specifically the relationship between concentration and molecular structure, and the impact of ionic strength on these phenomena. It highlights the research gap in understanding the transition from cylindrical to disk-like molecules and the significance of the study in advancing knowledge in the field." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Background" => "Background"
WARNING:llms.metrics:Ignoring 489 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 29 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 689 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 689 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Conclusion: nan, -1.000, nan
guideline_match_Motivation_Motivation: nan, 1.000, nan
guideline_match_Method_Method: 0.047, 0.136, 0.226
guideline_match_Result_Result: nan, 1.000, nan

> guideline_match_Conclusion_Background:
guideline_match: -0.504, -0.450, -0.394

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.006
tokens_per_sentence: 1.000, 1.006, 1.033
tokens_per_sample: 1.000, 1.012, 1.072
fkgl_readability: 11.406, 12.075, 12.719

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000

> tokens_diff:
mean: 12.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 38 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Motivation',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or '
  ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Background: A sentence that provides context, foundational knowledge, or ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Background: __REF__" => "Background"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 1000 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 667 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 667 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.681, 0.744, 0.796
guideline_match_Motivation_Motivation: -0.333, 0.667, 1.000
guideline_match_Method_Method: 0.304, 0.391, 0.477
guideline_match_Result_Result: nan, 1.000, nan

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: 0.536, 0.588, 0.636

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 4.080, 4.449, 4.794

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:

> tokens_diff:
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 39 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Motivation',
 'Motivation': 'Method',
 'Result': 'Result'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ...  instruments utilized.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Scientific concept: Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Result."" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Prediction "Concept: Mathematical equation" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Conclusion":
Conclusion" => "Conclusion"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Concept: Result" => "Result"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 724 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 993 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 176 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 676 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 676 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -0.848, -0.803, -0.748

> guideline_match_Motivation_Method:
mean: -1.000
guideline_match_Method_Motivation: -1.000, -0.993, -0.957
guideline_match_Result_Result: -0.143, 0.714, 1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: -0.883, -0.852, -0.813

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.000, 1.001, 1.005
tokens_per_sentence: 1.000, 1.008, 1.032
tokens_per_sample: 1.000, 1.015, 1.071
fkgl_readability: 6.070, 6.452, 6.842

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:

> sentences_diff:
mean: 1.000
tokens_diff: 3.000, 7.500, 12.000
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 40 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Result',
 'Motivation': 'Motivation',
 'Result': 'Method'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications, '
 " ... the research findings.\n'
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Conclusion: A sentence that summarizes the key takeaways, implications,  ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Method"." => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Result"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
__MOTIVATION__" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Scientific concept: Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
__MOTIVATION__" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Scientific concept: Motivation" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
REF - Result" => "Result"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text you provided, the category that best fits is:
REF
The text provides a description of the functional dependence of the hopping rates upon the interbase separation and the location of the crossover regime between the superexchange and the adenine–adenine hopping mechanism, which is a key scientific concept in the field of chemistry or physics." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Prediction "Concept: Reaction paths" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Prediction "Sure! Based on the text provided, the category is:
REF" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text you provided, the category that best fits is:
Scientific concept: Motivation" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Background" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Background."" => "Background"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, I would classify it under the category of "Method."" => "Method"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 994 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 725 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 998 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 177 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 639 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 639 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: 0.343, 0.421, 0.495
guideline_match_Motivation_Motivation: -0.333, 0.667, 1.000
guideline_match_Method_Result: -0.462, -0.353, -0.236
guideline_match_Result_Method: nan, -1.000, nan

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: 0.094, 0.162, 0.229

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.003, 1.008
tokens_per_sentence: 1.008, 1.045, 1.196
tokens_per_sample: 1.015, 1.090, 1.400
fkgl_readability: 7.193, 7.604, 8.017

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: nan, 1.000, nan
tokens_diff: 7.500, 22.500, 50.250
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:Processing label permutation 41 of 50:
{'Background': 'Background',
 'Conclusion': 'Conclusion',
 'Method': 'Method',
 'Motivation': 'Result',
 'Result': 'Motivation'}
INFO:__main__:Parameters:
{'add_previous_text': False,
 'add_task_prompt': True,
 'balanced': True,
 'concept': 'chatgpt',
 'domain': 'scientific',
 'empty_definition': False,
 'examples_per_label': 1,
 'guidelines': ('definition',),
 'label_noise': 'random',
 'n_permutations': 50,
 'seed': 17,
 'source_key': 'text'}
INFO:llms.evaluation:Loaded 30878 samples from /mnt/work/datasets/ART_Corpus/processed/train.csv
INFO:llms.evaluation:Sampling balanced data for 5 classes (maximum of 200 samples per class; seed=17)
INFO:llms.evaluation:Added 200 samples for class "Background"
INFO:llms.evaluation:Added 200 samples for class "Conclusion"
INFO:llms.evaluation:Added 200 samples for class "Method"
INFO:llms.evaluation:Added 200 samples for class "Objective"
INFO:llms.evaluation:Added 200 samples for class "Result"
INFO:llms.evaluation:Shuffling data using seed: 17
INFO:llms.evaluation:Evaluating llama-2-7b-chat on 1000 samples.
INFO:llms.inference:Using model: <class 'llms.classifiers.models.LlamaChatClassifier'>
INFO:llms.models.huggingface:Loading tokenizer /mnt/data/models/llama2/hf/7b-chat/...
INFO:llms.inference:Token statistics for input:
{'mean_tokens': 373.345,
 'mean_truncation': -3467.655,
 'total_tokens': 373345,
 'total_truncation': -3467655}
INFO:llms.models.base:System prompt: None
INFO:llms.models.base:Context prompt: ('Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that explains the reasons, objectives, or goals behind '
 ... ibutions to the field.\n"
 '\n'
 'Classify the text below into one of the categories listed above.\n'
 'Be concise and write only the category name.')
INFO:llms.models.base:Input prompt: ('Text: The control of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).')
INFO:llms.models.base:User prompt: 'Scientific concept:'
INFO:llms.models.base:Truncating input to 3839 max tokens
INFO:llms.models.base:Model kwargs:
{'dtype': torch.float16}
INFO:llms.models.base:Generation kwargs:
{'input_length_adjust': -1,
 'keep_generated_only': True,
 'max_new_tokens': 256,
 'memoizer_ignore_cache': False,
 'seed': 17,
 'temperature': 0.8}
INFO:llms.models.base:Model input:
('[INST] Consider the following concept categories:\n'
 '\n'
 '- Result: A sentence that explains the reasons, objectives, or goals behin ... ntrol of the tagging extent allows the simultaneous MS analysis '
 'of both the unmodified and modified peptide(s).\n'
 'Scientific concept: [/INST]')
INFO:llms.models.base:Output:
'Method'
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the measurement of a reaction and the dominant channel at room temperature, indicating the research findings and results. Therefore, it belongs to the category of "Motivation."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "The text belongs to the category "Motivation"." => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "The text provided can be classified under the category of "Results"." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Motivation" => "Motivation"
WARNING:llms.classifiers.models:Fixing prediction: "Result: The text explains the reasons, objectives, or goals behind the research, presenting the empirical findings and significance of the study." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the research methodology used in the study, specifically the type of plating bath used to deposit silver. It does not explain the reasons, objectives, or goals behind the research, nor does it present any empirical findings or data. Therefore, the category that best fits this text is "Method."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text explains the reasons, objectives, or goals behind the research, specifically the determination of the Ginzburg temperature in the context of a scientific study. It provides information about the research gap, the problem being addressed, the significance of the study, and why the research is important, making it a result category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information about the research gap, problem being addressed, and significance of the study, indicating that it falls under the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Sure! Based on the text provided, the category is:
Result" => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information on the outcome of the research, specifically the preparation of novel photocatalysts for photocatalytic water splitting. It mentions the materials used, their structure, and the conditions under which the reactions occurred. This falls under the category of "Result" because it explains the reasons, objectives, or goals behind the research." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text explains the reasons, objectives, or goals behind the research, specifically the importance of combining haemolysis with met-haemoglobin formation in the Photo-RBC test. It highlights the research gap and the problem being addressed, and provides insights into the significance of the study and why it is important." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information about the critical temperatures of the solutions, which is a result of the research." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a scientific concept or term, specifically the "C __SB__ isomer," which is likely a key finding or result of the research. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides a statement about the outcome of the treatment with antimicrobial agents, indicating that it is ineffective in some cases. This information falls under the category of "Result" as it explains the reasons or goals behind the research, specifically the finding that the treatment does not work in certain situations." => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the research findings, specifically a more compact fold in DSBO follows from SANS data for another protein, lysozyme. Therefore, it belongs to the category of Motivation." is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text explains the reasons, objectives, or goals behind the research, specifically the applications of the research in the field of pharmaceuticals, chiral sensors, and molecular devices. Therefore, the category for this text is "Result."" => "Result"
WARNING:llms.classifiers.models:Prediction "Result

The text provides information about the research method used to determine photosensitiser concentrations in blood, which falls under the category of "Result."" is not in labels: {'Background': 'Background', 'Motivation': 'Objective', 'Method': 'Method', 'Result': 'Result', 'Conclusion': 'Conclusion'}.
WARNING:llms.classifiers.models:Fixing prediction: "(x) Method" => "Method"
WARNING:llms.classifiers.models:Fixing prediction: "Result
The text provides information on the reasons, objectives, or goals behind the research, specifically the explanation of the research gap and the significance of the study. Therefore, it belongs to the "Result" category." => "Result"
WARNING:llms.classifiers.models:Fixing prediction: "Result

The text explains the reasons or goals behind the research, specifically the belief that DNA-binding is responsible for the antitumor activity of certain compounds, with intercalation being a necessary condition for this effect. Therefore, this text belongs to the "Result" category." => "Result"
WARNING:llms.metrics:Ignoring 461 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 553 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 999 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 7 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 997 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 996 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 764 null score values in confidence interval computation
WARNING:llms.metrics:Ignoring 763 null score values in confidence interval computation
INFO:llms.metrics:guideline_match_Background_Background: -1.000, -0.993, -0.974
guideline_match_Motivation_Result: nan, 1.000, nan
guideline_match_Method_Method: -0.575, -0.499, -0.414
guideline_match_Result_Motivation: -1.000, 0.333, 1.000

> guideline_match_Conclusion_Conclusion:
mean: 1.000
guideline_match: -0.797, -0.758, -0.716

> classification_metrics:

> source_stats:
sentences_per_sample: 1.227, 1.258, 1.293
tokens_per_sentence: 25.693, 26.796, 29.155
tokens_per_sample: 29.976, 31.359, 34.042
fkgl_readability: 13.428, 13.761, 14.104

> prediction_stats:
sentences_per_sample: 1.001, 1.004, 1.012
tokens_per_sentence: 1.020, 1.082, 1.208
tokens_per_sample: 1.037, 1.162, 1.424
fkgl_readability: 15.032, 15.567, 16.070

> reference_stats:
sentences_per_sample: nan, 1.000, nan
tokens_per_sentence: nan, 1.000, nan
tokens_per_sample: nan, 1.000, nan
fkgl_readability: 10.185, 10.740, 11.285

> length_diff:
sentences_diff: 1.000, 1.333, 2.000
tokens_diff: 31.000, 40.500, 56.500
exact_match: nan, 1.000, nan
partial_match: nan, 1.000, nan
INFO:__main__:No permutations remaining. Exiting loop.
INFO:__main__:Correlation with permutation_edit_distance:
permutation_edit_distance      1.000000
permutation_rouge1_distance    0.993481
permutation_rouge2_distance    0.998266
accuracy                            NaN
Name: permutation_edit_distance, dtype: float64
INFO:__main__:Correlation with permutation_rouge1_distance:
permutation_edit_distance      0.993481
permutation_rouge1_distance    1.000000
permutation_rouge2_distance    0.995893
accuracy                            NaN
Name: permutation_rouge1_distance, dtype: float64
INFO:__main__:Correlation with permutation_rouge2_distance:
permutation_edit_distance      0.998266
permutation_rouge1_distance    0.995893
permutation_rouge2_distance    1.000000
accuracy                            NaN
Name: permutation_rouge2_distance, dtype: float64
INFO:__main__:Permutation metric counts:
{0.0: 1, 0.4: 10, 0.6: 10, 0.8: 10, 1.0: 10}
